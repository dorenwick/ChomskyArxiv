Here is the outline for our strategy for reading through Chomskys work.

We need to first identify how to remove duplicates
of chomsky's works, and use title search to find which of our downloads are actually written by him.
We shall also need to figure out whether to prioritize epub or pdf versions, or mobi.
I think we will prioritize epub/mobi, and any that are pdf's from him shall be cleaned via adobe, so
we can extract paragraphs from them. (this is the hope!).

we can use grobid on the pdfs as well, which shall also be useful.
we will do that with chapters.

Now, we will describe our schema.
we want to use snowflake-xs to encode paragraph text, and sentence text too (possibly).

then, we have a structured schema in nosql database that will contain the following fields:



paragraph_int_id
type: (book, youtube, article, interview, debate, talk,...)
source: (name of book title, youtube video title, article title, interview, debate, talk, ect )
url: (chomsky.info link, youtube url, book url if theres an open url).
timestamp: (only applies if its a video)
location: (either a page number, or % of the way through the article, youtube video, book, ect.)
keyphrases: [] (list of keyphrases we have)
keynames:  [] (list of people associated or talked about)
questions: [] (list of questions appearing in the article text).
answers: [] (list of answers appearing in the article text. we may have a question_id and answer_id to say which questions are being answered.)
topic: (topic that chomsky is talking about. we may use something like BERTopic to create our own topics, and topic classifier here).

we will want a topic generator. It would be nice to have around 250-1000 topics. we should do this using
pca/dimensionality reduction and clustering, then finding keywords within cluster, then asking AI to give an appropriate topic name.



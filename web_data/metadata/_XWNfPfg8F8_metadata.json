{
  "duration": "PT22S",
  "view_count": "6264",
  "like_count": "78",
  "title": "How Intelligent Are Language Models Really? | Noah Chomsky",
  "description": "Welcome to episode #126 of Eye on AI with Craig Smith and Noam Chomsky.\n\nAre neural nets the key to understanding the human brain and language acquisition? In this conversation with renowned linguist and cognitive scientist Noam Chomsky, we delve into the limitations of large language models and the ongoing quest to uncover the mysteries of the human mind.\n\nTogether, we explore the historical development of research in this field, from Minsky’s thesis to Geoff Hinton’s goals for understanding the brain. We also discuss the potential harms and benefits of large language models, comparing them to the internal combustion engine and its differences from a gazelle running. We tackle the difficult task of studying the neurophysiology of human cognition and the ethical implications of invasive experiments.\n\nAs we consider language as a natural object, we discuss the works of notable figures such as Albert Einstein, Galileo, Leibniz, and Turing, and the similarities between language and biology.\n\nWe even entertain the possibility of extraterrestrial language and communication. Join us on this thought-provoking journey as we explore the intricacies of language, the brain, and our place in the cosmos.",
  "tags": [
    "Eye on AI",
    "episode 126",
    "Craig Smith",
    "Noam Chomsky",
    "neural nets",
    "human brain",
    "language acquisition",
    "limitations",
    "large language models",
    "mysteries of the human mind",
    "research"
  ],
  "published_at": "2023-12-21T14:00:32Z"
}
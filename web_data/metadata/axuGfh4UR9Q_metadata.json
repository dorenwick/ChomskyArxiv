{
  "duration": "PT3H36M51S",
  "view_count": "933324",
  "like_count": "8988",
  "title": "THE GHOST IN THE MACHINE",
  "description": "Noam Chomsky discusses how the \"mechanical philosophy\" that originated in the 17th century with thinkers like Galileo, Descartes and Newton viewed the universe as a grand machine that could in principle be understood through science. However, Newton's discovery of gravity, which involved \"action at a distance\" rather than direct physical contact, undermined this mechanical view.\n\nREST IN PEACE Dr. WALID SABA. Goodbye dear friend :( \n\nFull title: The Ghost in the Machine and the Limits of Human Understanding. \n\nPlease support us:\nPatreon: https://www.patreon.com/mlst\n\nProfessor Noam Chomsky is the most significant thinker of our generation.  Chomsky argues that since Newton, the goal of science has become more modest - rather than trying to understand the true nature of the universe, which may be beyond human comprehension, science aims to construct abstract models that are intelligible to us, even if the underlying reality remains a mystery. He suggests there may be inherent biological limits to human understanding, just as other animals have limits to their cognitive capacities.\n\nThe upshot is that we shouldn't necessarily expect a complete unification of scientific knowledge or for complex phenomena like mind and language to be fully explainable in terms of physics. Chomsky provocatively states that after Newton \"exorcised the machine\" by showing the mechanical philosophy was untenable, only the \"ghost\" of intelligibility was left in science, which now relies on human-constructed models rather than grasping the true essence of nature. Achieving a direct, intuitive understanding - \"exorcising the ghost\" - may simply lie beyond the cognitive horizons of the human species.\n\nPanel: \nDr. Tim Scarfe\nDr. Keith Duggar\nDr. Walid Saba \n\nPod version: https://anchor.fm/machinelearningstreettalk/episodes/MLST-78---Prof--NOAM-CHOMSKY-Special-Edition-e1l0760\nTranscript of Chomsky interview; https://whimsical.com/chomsky-transcript-WgFJLguL7JhzyNhsdgwATy\nOriginal corrupt recording: https://share.descript.com/view/N9KNaZTav27\n\n00:00:00 Kick off\n00:02:24 C1: LeCun's recent position paper on AI, JEPA, Schmidhuber, EBMs\n00:48:38 C2: Emergent abilities in LLMs paper\n00:51:32 C3: Empiricism\n01:25:33 C4: Cognitive Templates\n01:35:47 C5: The Ghost in the Machine\n02:00:08 C6: Connectionism and Cognitive Architecture: A Critical Analysis by Fodor and Pylyshyn\n02:20:12 C7: We deep-faked Chomsky\n02:29:58 C8: Language\n02:34:34 C9: Chomsky interview kick-off!\n02:35:32 Q1: Large Language Models such as GPT-3\n02:39:07 Q2: Connectionism and radical empiricism\n02:44:37 Q3: Hybrid systems such as neurosymbolic\n02:48:40 Q4: Computationalism silicon vs biological\n02:53:21 Q5: Limits of human understanding\n03:00:39 Q6: Semantics state-of-the-art\n03:06:36 Q7: Universal grammar, I-Language, and language of thought\n03:16:20 Q8: Profound and enduring misunderstandings\n03:25:34 Q9: Greatest remaining mysteries science and philosophy\n03:33:04 Debrief and 'Chuckles' from Chomsky\n\nReferences;\n\nLeCun Path to Autonomous AI paper\nhttps://openreview.net/forum?id=BZ5a1r-kVsf\n\nTim’s marked up version:\nhttps://acrobat.adobe.com/link/review?uri=urn:aaid:scds:US:8c5260f5-8959-3f11-bb3b-befb3bc65f13\n\nEmergent Abilities of Large Language Models [Wei et al] 2022\nhttps://arxiv.org/abs/2206.07682\n\nConnectionism and Cognitive Architecture: A Critical Analysis [Fodor, Pylyshyn] 1988\nhttp://ruccs.rutgers.edu/images/personal-zenon-pylyshyn/docs/jaf.pdf\n\nGhost in the machine\nhttps://psychology.fandom.com/wiki/Ghost_in_the_machine\nhttps://forum.wordreference.com/threads/in-an-aristotelian-sense.3350478/\nhttps://news.ycombinator.com/item?id=26448901 (thanks to user tikwidd for your analysis)\n\nNoam Chomsky in Greece: Philosophies of Democracy (1994) [Language chapter]\nhttps://www.youtube.com/watch?v=-kL0UNWcWFc\n\nRichard Feynman clip\nhttps://vimeo.com/340695809\n\nChomsky Bryan Magee BBC interview:\nhttps://www.youtube.com/watch?v=PxvSQnmcYLo\n\nRandy Gallistel's work (question 3)\nHelmholtz “NNs : they’ve damn slow”\nPurkinje cells\n\nBarbara Partee\nhttps://www.youtube.com/watch?v=aA_T20HAzyY\n\nIris Berent\nhttps://cos.northeastern.edu/people/iris-berent/\n\nPenrose Orch OR\nhttps://en.wikipedia.org/wiki/Orchestrated_objective_reduction\nhttps://en.wikipedia.org/wiki/Shadows_of_the_Mind\n\nFodor “The Language of Thought”\nhttps://www.amazon.com/Language-Thought/dp/0674510305\n\nLeast Effort\nhttp://materias.df.uba.ar/dnla2019c1/files/2019/03/scaling_in_language.pdf\n\nstructure dependence in grammar formation\nhttps://www.jstor.org/stable/415004\nhttps://www.amazon.com/Minimalist-Program-MIT-Press/dp/0262527340\n\nthree models\nhttps://chomsky.info/wp-content/uploads/195609-.pdf\nhttps://en.wikipedia.org/wiki/Transformational_grammar\nhttps://www.amazon.com/Aspects-Theory-Syntax-Noam-Chomsky/dp/0262530074\n\nDarwin's problem\nhttps://chomsky.info/20140826/\n\nDescartes's problem\nhttps://en.wikipedia.org/wiki/Mind%E2%80%93body_problem\n\nControl Theory\nhttps://en.wikipedia.org/wiki/Control_(linguistics)",
  "tags": [],
  "published_at": "2022-07-10T00:50:50Z"
}
Video URL: https://www.youtube.com/watch?v=Rgd8BnZ2-iw

okay well
um I'm uh Robert freeden the professor
in the Linguistics program at princ
University and it's my pleasure to
welcome you to this talk by n
Chomsky uh n Chomsky began work on
generative grammar as a senior at the
University of
Pennsylvania in a senior thesis in
1949 um and has continued since then
with um hard to describe the the output
uh puts most of us to shame um and he's
still a major contributor in the field I
give you no
thanks well uh Bob asked me to say a few
words about uh uh where I think the
field has gone in roughly 60 plus years
uh as
he made clear it's obviously a personal
perspective other people see it very
differently uh maybe
rightly uh uh since he
mentioned
1949 and since I'm supposed to start
from the
beginning if you don't mind a personal
anecdote one of the things that got me
interested in the field actually around
1946 was the
realization that the Bible is mist
translated the Bible begins in the
beginning God created that's
mistranslation that's a mistranslation
based on a grammatical error by the mtic
scholars who put the vowels in around
the 8th
Century uh any of you know Hebrew you
can ought to be able to figure out
pretty quickly what the error is it's
been mistranslated for a thousand years
and I figured at the time if the first
couple of words of the Bible can be
wrong in the authoritative text and
wrong in the translation and nobody
noticed it for a thousand years there
got to be something interesting to learn
about
language in fact the more you you look
the more you find that everything is
misunderstood and when you think about a
little more that's not terribly
surprising that's the way the history of
science has worked so if you take a look
at say the Galilean revolution around 6
1800 afterwards what it was mainly a
large to a large extent based on was the
discovery that everything everyone
believed was wrong about very simple
things so for
Millennia uh there was an answer to a
very simple question uh if I if this cup
is full of water boiling water let's say
and I let go of it the cou will fall and
the steam will rise and it was a
classical answer to that from
Rian science they're seeking their
natural place and for thousands of years
that was considered a fine answer except
Galileo and a couple of others decided
to be puzzled about it and as soon as
they were they saw at once it's not an
answer and as soon as you looked a
little further you found that all your
intuitions about falling bodies are
totally wrong you know and there modern
science starts and the my feeling is
we've been in a kind of preg Galilean
stage uh and uh we've just got to learn
and by now everybody who's working in
the field knows they don't have to learn
that you just have to be puzzled by the
very simplest phenomena in fact open a
look at a corpus or open a book and pick
out the first sentence and it's puzzling
why should it be that way not some other
way and just about everything you look
at is just as in the physical world and
my own aha or leness was uh when I
realized that the word in the beginning
were mistranslated and a mistranslation
that actually is based on a grammatical
error that went back a thousand years
and it's transparent you know as soon as
you look at it if you know anything
about Hebrew grammar you see this is
impossible it's grammatically impossible
that's also clear what it was supposed
to be remember they put in vowels the
consonants were there and they put the
bows in wrong but uh so that's in the
beginning well uh things kind of began
to get cryst there's other things to say
about that but I I'll talk about it but
uh by the early
50s things were kind of beginning to
fall into place there was an Orthodoxy
strict Orthodoxy I was at Harvard you
know kind of main intellectual Center in
these areas
and there dual Orthodoxy one was
structural Linguistics and the other was
behavioral psychology and the two meshed
though they didn't say so there were
about three people who didn't believe
the
Orthodoxy as grad students it's where
things usually come from uh I was one
Mars tally long friend and colleague was
another and the third was Eric lenberg
who went on to found biology of language
and we talked to each other and started
reading things and doing various things
and the gradually some ideas began to
crystallize which only became clearer
considerably later so this will be an
acronis but that's the way things
usually are as you know you sort of
think you understand something and 20
years later you see you really did
understand it but you didn't know you
understood it and so on uh the some of
these assumptions that began to take
shape seem to me as if they ought to be
truisms in fact they are
truisms but they're highly contested in
fact vigorously denied right to the
present so maybe it's worth mentioning
them uh one thing that should is and
should be regarded as a trism is that
language is spoken by people doesn't
sound very remarkable so it's something
that individuals do and they don't do it
because of something in their feet you
know they do it because of something in
mostly in their brains so language
capacity must be a b biological property
uh that's mostly in the some part of the
brain we now know some things about
where and how but it's just got to be
there which means that the core problem
of language should be viewed from the
point of view what years later came to
be called biolinguistics the study of a
internal individual biological property
uh which manifests itself in action like
others you
know say motor organization or Vision or
anything else it should be just normal
science study of some biological
capacity uh and I think that's true of
all cognitive capacities but that's
another story which I won't go into also
highly
contested uh a
second assumption which is again should
be obvious it gradually became clear is
an actually an Insight that goes back to
decart I think he was the first to
formulate it with any
Clarity and that is that ordinary use of
language and let me stress use uh is has
a kind of creative capacity normal
ordinary use of language so it's
constantly Innovative it's
unbounded it's appropriate to
circumstances typically but not caused
by circumstances or even elicited by
them it's a critical difference which
wasn't understood then and isn't
understood now uh and is H actually the
basis for most of cartisian science
what's called philosophy uh well it's
kind of interesting that you don't find
this in the long history of the subject
in fact the only person I've been able
to find maybe some Scholars here can
fill in details is Galileo who had a
kind of a weak version of it but he was
talking about the alphabet which is a
reflection of this capacity not the
capacity uh that one was pointed out to
me by Irwin panovski who you may know
great scholar uh but if there's anything
else I haven't found it I it's perfectly
obvious from a moment's thought that
that's what language use is but not
there if you get the modern period
virtually nothing in fact if you uh uh
which is an interesting question in
itself how can these obvious things not
only not be seen but be vigorously and
often passionately denied you know up to
the present uh well that's the second uh
the
uh uh actually about 50 when I got
interested in history I started looking
at it considerably and I did find some
later things which brought it up there's
a phrase of f Hol I've quoted a number
of times that has been very seriously
misunderstood maybe my fault but uh by
now it's widely used and the language
involves infinite use of finite
means that's what he said exactly what
he meant you know not so obvious pretty
obscure if you read it but whatever it
was he was talking about use
okay he was talking about infinite use
of finite means now we know nothing
about the infinite use I mean
essentially just it's there but we've
learned a lot about the means in fact
most of the work in the last 60 odd
years is about the means that enter into
the infinite use which leaves us a long
distance away from the classical and
very intriguing problems about what is
it about uh
human it may be complet it may be
totally human as deart thought we don't
know that that's wrong uh but uh
whatever it is it's an elementary fact
about humans manifest itself in other
ways kind of the core of human nature we
don't understand it don't know how to
study it but you can get a uh in some
areas and language is one of them one of
the very few you can learn a lot about
the means that are put to use different
question but an interesting one
well that's uh the conclusion from that
I think in retrospect should have been
obvious couple thousand years ago
certainly should have been obvious in
1950 is that uh you should study
language from what's later been called
the biolinguistic perspective and with a
focus on what's now called eye language
at least what I call eye language which
is just gra grammar in one of the
earlier uses of the term grammar
ambiguous term so this was technical
proposal to get rid of the ambiguity so
some system that's internal individual
and thanks to English spelling uh is
viewed intentionally with an S so you're
interested in the actual procedure not
the this is kind of irrelevant what the
output of the procedure is some
ancillary phenomenon Corpus or something
like that data not what you're looking
at uh so that's I language earlier years
grammar same concept nothing do accept
the term uh and so an I language means
some kind of generative procedure uh any
system of means that's infinite
unbounded uh has got to
have We Now understand has to have some
generative procedure that uh recursive
procedure that character characterizes
it and that's what you're interested in
the actual procedure not its output
actually some years later this was
discussed in a kind of an interesting
way but a somewhat orthogonal which is
also not understood by Dave Maher who I
knew pretty well and was actually using
grammatical
models and he as you should know
developed an approach to cognitive
science generally which uh separated the
computational level which is kind of
like a characterization of the problem
the algorithmic level where you have a
procedure that deals with the problem
and uh
uh forget what you called it a material
Level where you look at how it's all
working out in the brain uh it's it's
the analogy was supposed to be something
like competence and performance uh but
it's not quite the same because he was
studying and this is quite important he
was studying input processes vision and
for input processes yes there's an
algorithm so you can study the problem
of say three-dimensional Vision you know
how object recognition you can State
what the problem is computational level
you can look at the algorithm by which
it's carried out which is quite
surprising when you look at it as very
odd properties which nobody ever knew
until recently and you can look at the
mechanisms but for a competent system a
generative system like language there's
no algorithm and nothing is being done
you know it's just a characterization of
an infinite Set uh finite
characterization of an infinite Set uh
but there's no algorithm so you can't
carry over the mar model for this
actually this is kind of similar to
Jerry foder work on modularity which you
may know he's his modules are input
systems but the kind of modules that are
studied and should be studied in my view
in cognitive science theories are
Central systems different Randy gallis
work is like this that's what I always
meant by it so and that's what Jerry
says can't exist can't be a modular
Central system but it has to there has
to be internal modules that do
particular things and they are not input
or output systems so you have to be
really careful about applying these
Notions sound similar but not quite uh
well uh it's
uh I mean the sort of core question you
have to answer once you adopt this kind
of framework I the most Elementary
question is what's a
language it's again interesting to see
how this question is ignored in the
literature of a couple thousand years
it's instructive to take a look as I
take the modern period you know soer
Bloomfield Quin philosopher did most of
the work on it the only proposals about
what language is make absolutely no
sense at all as soon as you look at them
uh in fact Quin gives contradictory
answers almost the same Pages neither of
which makes any sense uh one of his
answers is essentially taken from
Bloomfield who defines you know the
great in his book language language is
uh
uh the totality of Expressions that are
used in a piece in a speech
Community that's completely meaningless
you know I won't talk about it but think
about it uh one of coin's proposals is
about the same the other one contradicts
it if you look back at suur there's
essentially nothing I mean it's a social
contract of some kind uh well okay but
uh it didn't tell you anything about
like languages what language has to be
the core question is at least a
generative process at least that in
other words an eye language which is
just a generous process and then come
questions about what it is well there
are plenty of other questions to ask
about language significant ones
acquisition use if you could possibly
study it which you can't uh any serious
way uh neural
representation hisory his dionic
Linguistics evolution of language which
is incredibly confused with historical
Linguistics and modern work in a
astonishing fashion if some time I'll
come back to it but uh U those are all
questions you can investigate but for
any of them you can proceed only as far
as you have some characterization of
what a language is like you can't study
acquisition of language unless you know
what language is now you don't have to
know everything of course you know like
you can study evolution of the eye
without knowing everything about the eye
but it's certainly not enough just to
know that eyes are used to watch
television I mean no biologist would
study the evolution of the eye on that
basis you take a look at the work on
what's called evolution of language it's
exactly what it is language is used for
communication sometimes and a million
other things so therefore will study
that and of course get zero results as
you would if you studied evolution of
the eye knowing nothing except it's used
to watch television now these ought to
be Elementary observations that's kind
of embarrassing to talk about them
except that they're rampant in current
work in the field and we should ask why
for a lot of you that's the field you're
getting into well uh uh there's another
truism
or ought to be and that is that there's
some genetic component in humans that
makes it possible for us to do what
we're doing uh but uh makes it
impossible
for you know we're called our nearest
relatives you know 10 million years
apart uh say
chimpanzees they have about the same
auditory system that humans have that's
been recently discovered in fact they
even uh pick out the same phonetic
features that are used in distinctive
features in
language however if you say have a
chimpanzee and your you know baby sister
or baby if you're old enough who's are
stuck from birth in front of a mass of
noise uh the infant human infant
immediately picks out of the noise as
something that's language relevant which
is kind of miraculous no nobody knows
how that's done but they do it instantly
reflexively some of it we now know is
even prenatally on the other hand for
another animal with the same auditory
system it's just noise and it's it goes
the other way too uh other organisms
will pick out relevant material from the
noise General noise environmental noise
and humans won't see anything unless
they kind of study it from the outside
as scientists well from that alone it
follows there got to be a genetic
component and if you go on to the next
step you know a couple of months later
it just becomes more obvious they're
doing very specific things that
consistently you know very uniform ways
uh of course it's driven by data but so
is everything on the other hand it's
going on a path which is not determined
by data you can see that from the
elementary fact that no other organism
does it plus that there's no way of
doing it from just from data if you look
at it and uh and they get to the
capacity that we're using very early in
fact the better experimental work gets
the younger and younger are the
capacities noted in fact there's even
some work which is suggestive some of
you guys know about it that uh by around
2 years old the child probably knows the
whole
language uh can't manifest it but there
pretty good evidence that can be
elicited
uh
that's the most interesting cases are
the Helen Keller type case she was 20
months old when she lost language
capacity to use at least but she
recovered it on the basis of almost no
data you know just touch in fact she
learned her she invented the technique
that's now used to teach a deaf blind
it's called the Domo where you sort of
put your hand on someone's face you get
information from the vocal cords and the
cheek on the basis of that you got
fantastic linguistic capacity which is
almost impossible unless she knew
everything
uh adding to this is something about
which there aren't enough cases to draw
a confident conclusion but they seem
systematic if the loss was before about
18 months there's never been a case of
recovery so it looks as if there's
something going on right around then
which is basically giving Lang the
language you know then you sort of add
details or refine it or something like
that well whatever this is and it seems
to be independent of other cognitive
capacities there quite good evidence now
for radical dissociations with other
capacities well these are kind of some
of the you even if this detail isn't
right you know the general picture is
and uh uh it seems to it's more and more
evidence it just has to be an internally
directed process from the most obvious
to much more complex arguments than what
I've given uh so so there's got to be a
genetic component there's a technical
name for the generative component it's
called
ug okay Universal grammar that's taking
over a traditional phrase for a new
context the existence of ug is hotly
denied hotly denied
overwhelmingly huge literature saying
this is ridiculous so what the
literature is saying everything's a
miracle that's exactly what it's saying
because there's no alternative there's
no coherent alternative now there are
proposals so there are proposals about
shared intentionality you know culture
these are interesting proposals I mean
they give hand waving a bad name
actually if if you look at them there's
just nothing there there can't possibly
be anything there if only because of
dissoc
dissociations uh or because of timing
like a two-year-old don't know anything
about the culture you know and shared
intentionality like autistic kids don't
have it they speak fine and it goes on
and on and furthermore there's nothing
that comes out of it zero you know uh
but it's very widely held you can read
about it from uh uh you know technical
articles in the cognitive science
journals to times literary supplement
and all across the board except that
it's totally vacuous and can't make any
sense just we have to think about it you
see it can't make any sense well uh
there are more specific proposals which
are of some interest because you can
investigate them at least so one
proposal is just monstrous memory like
you memorize
everything well again it's it's infinite
so you're not going to be able to
memorize everything furthermore even if
you take normal
usage which actually was studied by
George Miller who was here late George
Miller 60 years ago he looked at
sentences of 8th grade reading level
reader digest and calculated how much
you have to memorize if you could
understand those SS it turns out more
than the number of particles in the
universe you know uh if you reduce it by
replacing the words by categories which
is not a trivial matter it's basically
the same the numbers are so big doesn't
make any difference if you put in
phrases which is often done you've given
the game away because the phrases have
to be recursively generated so you're
done you know well that's the
memorization story uh there are
interesting there's an industry of U
statistical
models uh which are are quite
interesting to look at um there's a
there a kind of Hysteria about the
importance of statistics and you know
sophisticated basian Etc there a couple
of phrases you have to use when you
write about this and and it's not zero I
mean if you look back say to the
beginning early
50s there was an argument actually I
wrote about it back in the mid-50s that
you should be able to detect words from
phrases from continue not phras from
continued text to isolate them just by
looking at transition probabilities
that's mentioned in logical structure of
linguistic Theory actually it's mention
as a footnote because it looked obvious
there doesn't seem to be any other
evidence uh well if that were true you
could do something with statistical
models whether this has anything to do
with language acquisition is a totally
different story I mean kids don't learn
words by picking them out of continuous
discourse you know they know a lot
before they're looking at the discourse
anyhow no point pursuing it it turns out
to be wrong Charles showed that years
ago uh you can get something but only if
you add ug principles and their
subsequent work by shla P Humber others
which shows you got to know quite a lot
even to do this that's one of the very
few examples uh there's another
interesting one interesting ones in
Charles's work again one thing that he
showed is there there's been a lot of
stuff study in recent years of
connectionist work and others on trying
to uh account for the learning of
irregular verbs it's kind of a
peripheral problem it was never studied
very much but recently it has been uh
none of it works except for Charles's
proposal which gives a very interesting
answer to the question of how irregular
verbs are learned by
intermingling uh probabilistic arguments
with ug principles and as far as I know
everything in this field you can correct
me if I'm wrong if it gets anywhere
works that way or else it deals with
different problems like uh processing or
communication and so on okay everyone
always agreed sure statistical models
are significant there uh but again you
can read uh very uh there's plenty of
literature A lot of it very triumphalist
in the technical journals listing all
kind of great results that been achieved
everyone you look at when you look at it
take it apart it achieved absolutely
nothing except a total IR remediable
failure but it just goes on and on this
is uh kind of Unstoppable and so taking
over a lot of cognitive science well
uh actually the only again the only work
that I know of change it's wrong
is kind of around the margins as far as
the nature of the system is concerned
it's the only question we're asking and
uh and its acquisition and maybe its use
and involves an intermingling of ug
principles with probabilistic arguments
Charles's book is about how these
interact uh so I think the conclusion is
about the same after it should be the
same adopt the biolinguistic perspective
study the core topic is ey language
generative procedure and you got to try
to figure out what ug is what is the
genetic basis incidentally there's a lot
of literature pointing out sort of
saying gosh after 50 years these guys
have been studying the UG and they still
don't know what it is must be something
wrong uh try studying the genetic basis
for having blue eyes you know or let
alone any complex trait I mean it's
known just take a look the look at the
your favorite Advanced text and biology
evolutionary biology ology they point
out to quote it's fish difficult to find
the genetic basis for almost anything I
it's not that anyone denies that it
exists but organisms are complex
creatures you know to try to pull out
the properties that are genetic and
separate them from lots of interacting
factors is no small trick uh even when
you have a hundreds of millions of
dollars from the NSF for experimentation
and so on and so forth and to do it for
a trait as complex as language a
cognitive trait that it's beyond
fishlyn one's written a complete grammar
of any language I
mean it's not even worth talking about
we you don't even know exactly what
you're supposed to describe so what's in
it and what isn't in it and so on and so
forth these are impossible goals never
approached in the SC never formulated in
The Sciences because they're so crazy
but it's somehow applied to this one
field which is supposed to be different
from anything in the Sciences well uh
the idea that uh you can have infinite
output from a finite mechanism M that
does go back to classical Antiquity so
ukian geometry says morsus like that but
it's worth remembering that ukian
geometry wasn't formalized until about a
century ago it was largely
intuitive and in fact the general
concepts that's by Hilbert uh the
general concepts of uh what it means for
a finite object to have an infinite
yield that wasn't really clarified till
the 19 30s and 40s by now it's
understood and by now everybody knows it
you all got a laptop computer it's a
stored program computer the storage
program if it's the right program
generates an infinite output of course
it can only go up to a certain point
unless you add memory uh but and that's
often confused in the literature uh when
you add me say arithmetic you can have a
program for multiplication and it'll
stop up to you know some big number but
the point is if you add memory it'll go
on without changing the program that's
the crucial part uh the fact that uh and
the brain has got to be the same and
language has got to be the same this
crucial fact going on without changing
the program again is greatly
misunderstood in the even in the
technical literature of computational
cognitive science that's why most of the
connectionist models don't make any
sense if you add
The Next Step you got to change the
whole program you know so it's doing
nothing you know it's just showing that
some finite output can be handled with
what amounts to a list yeah sure but uh
no interest well these are things that
ought to be
understood
uh one I mentioned that uh IE language
should be studied in the context of
generative processes recursive
processes uh it's part of recursive
function Theory touring machine Theory
very narrow part of it uh the uh uh the
concept of recursion is hopelessly
misunderstood in the technical
linguistic literature for one thing
there's a debate about
uh even whether it's has to be infinite
no it doesn't have to be infinite you
can have a recursive function with no
output at all in fact those are some of
the most interesting ones but uh uh it
doesn't have to be infinite though in
fact in the case of human language
apparently it's always infinite uh
recursion is constantly confused with
embedding or even self- embedding which
are special cases but only special cases
and the uh
this
okay we can go on if
you don't mind being blind death
actually I just came back from Gaza
where this happens every hour or
two okay the the generator kicked
in
what the uh
uh some somebody doesn't like
us
okay uh there is another thing that's if
you look at actual language output it
seems a very strange gaps in it actually
it's a classic study of this which is
very important it isn't read enough
Richard Kan an article by one of your
colleagues Ken hail about 35 years ago
on cultural gaps it's very much worth
reading particularly because of a lot of
complete nonsense that's flooding the
field now about languages that allegedly
don't have this or that in fact every
case that's mentioned in the recent
literature is discussed by
can much more seriously because he's a
serious linguist and gives good
arguments showing how these apparent
gaps are simply
restrict narrow restrictions on ug
principles that the people all know uh
then gives plenty of evidence from
Australian languages other languages so
that one's quite worthy he also has some
pretty interesting comments about the
universal nature of relative clauses an
embedded relative clause which are quite
interesting worth thinking about anyhow
that's uh these are things that are be
known too so whatever an eye language is
it's something that gives an it's finite
object gives the brain gives an infinite
array of hierarchically structured
Expressions uh Each of which gets an
interpretation at at least maybe at
least maybe at most two other cognitive
systems that one it can be externalized
somehow uh so doesn't have to be in fact
most of our language use isn't
externalized but uh it can be
externalized at sensory motor system we
now know that that's modality
independent pretty much can usually
speech what but could be sign or touch
or something else uh it seems to be
independent of
modality uh it also appears to vary a
lot and probably does vary a lot which
is an interesting fact uh one of the
many things that indicates I think that
the externalization to the sensory motor
system is probably some ancillary
secondary fact about language kind of
tacked onto it not Central uh more
Central appears to be the fact that it's
it interacts with what are roughly
called thought
systems technical term is conceptual
intentional systems intentional with a t
not that the technical term adds
anything particular except sounding
fancy but so there's got to be an
externalization of that system whatever
it is and they're very fundamental
questions about which part of that
mapping of the internal computation is
part of the external system and which is
part of the internal system and that
goes right to the heart of a lot of
questions like say an AFA where is it
you know I we usually assume it's
internal to eye language but that's only
because we have some ideas to how to
deal with it and so you can kind of a
lot of interesting work on how how it
works but you there's got to be plenty
of computation in that outer system too
so who knows where the boundary is and
you get here into quite interesting
questions about Fon language which I
won't talk about those are important
topics uh it's often argued that
uh
if the
a comp any computational system that has
roughly these properties is going to
have embedded in it somewhere an
operation that takes things that have
already been generated and makes a
bigger thing uh it may not be put that
way like it may be a Fran ancestral or
it could be a system of axioms or
whatever but somewhere embedded in it is
that operation there's no way to get
around that and notice that look that's
operations a lot of people me and others
call merge so there's got to be some
operation merge that has that property
well merge automatically gives
hierarchic structures
automatically it's putting things
together so you get a structure you add
something else get a bigger structure so
it is produc it has the right properties
it's producing hierarchic infinite
number of hierarchic structures which
didn't have to get interpreted by
process that are there's a lot of study
of them at the
uh towards the sensory motor side some
towards the conceptual intentional side
but a lot of it has the problem that I
mentioned which isn't investigated where
is it is it inside the eye language or
outside the eye language not easy to
answer because we have no we have
independent evidence about the sensory
motor system like you can hear it but
almost nothing about the other systems
you're kind of wandering around a
confused field there with a number of
quite interesting questions I won't go
into them the uh uh it's often argued
that there are simpler things that merge
the usual proposal is
concatenation uh concatenation is a more
complex notion it presupposes merge and
furthermore it presupposes
ordering uh it looks as if it's non
hierarchical but that's only because it
has an extra operation associativity
which knocks out the hierarchy
uh so it's more complex there is a
version Norbert hornstein which
abstracts away from ordering but still
has has to have the uh structure the
operation that strikes out structure a
lot of the study of formal Linguistics
about all of it in fact deals with weak
gener capacity know the weak gener of
capacity say of phrase structure
grammars uh that's considered to be simp
simpler than the study of eye language
it's much more complex because weak
generative capacity is a derivative
notion you have to derive it from the
eye Language by knocking out the
structure you take a look at a phrase
structure grammar doesn't give you it
doesn't weakly generate it strongly
generates structures you can wipe out
the structure and look at what's left
which is already problematic because
it's more complex uh and it's doubly
problematic because you don't know
what's supposed to be in there uh every
linguist knows that if you open a
technical article and say linguistic
inquiry you're going to get expressions
with stars and question marks and star
question mark and all sorts of other
things and these are very interesting a
lot of the most important work has to do
with these distinctions so why is there
a distinction between say subjacency and
ECP violations that's interesting but
it's all at the level
of technically what wouldn't be
generated by it weak generative capacity
and this is not a new observation this
is discussed at length in the
1950s chapter of logical structure of
linguistic Theory devoted to it do
answer the question but talks about some
of the problems so the study of weak
gener capacity is first of all
derivative more complex based on
arbitrary stipulation ations it's not
clear that it has anything to do with
language I mean you know I worked on it
I thought it was fun but it's a small
branch of formal mathem of formal logic
or mathematics some vague relations to
language but not much it's worth
thinking through as well uh the uh going
back to what I still haven't started
what happened for the last 60 years but
the early proposals back in the 50s I
mean as soon as it was realized that
everything you look at is completely
problematic from the first phrase of the
Bible to the next sentence you look at
uh the proposals started coming along as
to how to deal with it well the early
proposals back say in the 50s were
extremely complex I won't review them
but if you look at the say my proposals
others they assumed a lot of complex
mechanisms which seemed necessary it
didn't seem any other way just to
describe the data in different languages
and uh I think the history of the field
at least that the theoretical level
since then has been an effort to try
to simplify it to remove the
stipulations the complexity the
mechanisms and see if you can get to
principles from which a lot of these
things follow uh there should be
nothing problematic about this that's
what's called science
uh science is the search for simple
mechanisms that account for complex
phenomena uh anything else is U you know
flower collecting so which is fine
nothing wrong with that but uh it's not
science so there's nothing problematic
about it I w't won't run through the
steps which you're all most of you at
least are familiar with uh it's been a
kind of steady progress in that in
recent years work in this Direction has
been given another name which was a
mistake I think my mistake it's been
called the minimalist program and that L
anything you say about language there's
one thing you can be certain of it's
going to elicit enormous confusion and
misunderstanding that's a kind of a
theorem you know I don't know what it
follows from but it's a fact you know uh
and the minimalist program is totally
misunderstood it's constantly described
as a theory and then there's arguments
that the theory is falsified by this
it's not a theory it's just science it's
trying to find the best explanation for
complex
phenomena uh eliminating stipulations
where you can eliminating complex
mechanisms showing how they can be
derived by deeper principles and in fact
just deepening explanation that's what
inquiry is about you know the minimalist
program is just a seamless continuation
of efforts that went on from
the first notice that we don't
understand anything uh well it did uh
the program did Su suggest some new
research programs which you know the
research program is right is it's not
true or false you know either it's
useful or isn't useful I think this one
has been useful uh the research program
that it suggests is to start by
assuming uh that a language is
essentially perfect that it
it precis in the most optimal fashion
satisfies the interface conditions those
of you who took courses of mine since
about 1980 will remember that every
course started by saying okay let's
assume this and then started looking at
the facts and everything fell apart so
didn't get anywhere but uh the uh around
the '90s the program started to make
more sense and my guess is it's going to
turn out to be the right program it's
hard to show but I think that's kind of
a long run goal that people might keep
in mind and I think there's reasons for
it uh but U that what that means is try
to formulate what's sometimes called a
strong minimalist thesis not the strong
minimalist thesis we don't know enough
to do that but one that looks plausible
the one that says here would be a
perfect solution to the external
conditions on eye language a couple of
ideas about what that should be and then
AR raise two kinds of questions one of
the kinds of questions is descriptive
when you apply when you take a look at
the data of wide variety of languages
from this starting point you find a lot
that doesn't work so the first almost
automatically so the first descriptive
problem is see if you can show that what
doesn't seem to work is based on
misanalysis of the data or misformation
of the principles and if you can do that
okay you've Advanced the program uh and
I think there's been a a lot of work
going in that direction nowhere near the
end but quite a lot the other question
you can ask is uh kind of more abstract
and that is assuming that something like
your strong M thesis is correct what
does that tell you about the nature of
language the architecture of language or
maybe of cognition generally and
actually I think it tells you quite a
lot which more than generally
appreciated well
uh the uh well as I said every let's
just proceed assume that this is the
right way to approach things uh the I
mentioned that
any strong minimalist thesis in fact any
approach to language which is going to
have to assume uh a merge like operation
so the question is what it is uh well of
course if you if just proceeding in the
normal manner of science that is
following the minimalist program which
is all it is at least you'll start by
assuming that the operation is as simple
as possible okay if it goes wrong you
complicate it as simple as possible
means that when you merge say two things
X and Y and neither of them will change
so you're minimizing I me the overriding
principle that one ought to try to keep
to is a sort of minimal
computation try to show that the system
is has has at is as at least the least
messy it has to be so minimal
computation I don't think that's a ug
principle I think it's sometimes called
a third Factor principle it's an
overriding principle that works for the
Sciences all together it's maybe it's a
law of nature or something or law of
human cognition whatever you think it is
but it it determines what counts as
rational inquiry so look for minimal
communication computation uh that means
you're not going to that the merge merge
XY is not going to change either X or Y
that's called the no tampering condition
but it's just minimal
computation uh which is has interesting
consequences very interesting
consequences the other uh condition at
autom meet is that it's
unordered that's simpler than being
ordered so the least computation will
take X and Y and not change them and
leave them unordered which means it just
forms the set XY that's what it amounts
to that would be the perfect answer okay
here we get into a real morass because
where does ordering come from I it's all
over the place uh and lot of complicated
issues related to it well one
thing that shouldn't strike you right
away is that uh ordering is re and other
arrangements in fact are required at the
sensory motor system like we can't talk
unordered sets you know hierarchically
structured unordered sets so something's
going on at least in the externalization
that's imposing order and in fact other
arrangements like in sign there more
than order and even in speech not pro
and so on but at least order so maybe
it's a reflex of linearization of
externalization one possibility if
that's true it shouldn't and just by the
general architecture of the system it
shouldn't enter into narrow syntax and
sematic interpretation you know the
mapping to the CI interface and I think
there's a fair amount of evidence that
that may be true these interpretations
typically seem to involve hierarchy not
order they work the same with different
orders uh and that suggests that
collection of observations suggests that
maybe ordering is just a an artifact
non-linguistic artifact
connected with the fact that this system
has to get the sensory motor system well
if you take a look at the evolutionary
as I mentioned the the study of
evolution of language is such a morass
that I don't even want to get into it
it's I have never seen so much confusion
on any topic literally actually begins
from the name of the topic one of the
problems with the study there's a huge
Library growing library on evolution of
language and one pretty obvious problem
with it the topic doesn't exist
languages don't
evolve uh evolution is something that
happens to
organisms languages don't have genes you
know they don't evolve uh languages
change but that's not Evolution and if
you look at the literature it's actually
studying change and it's not even
studying change of language it's
studying change of communication
practices and it's not even studying
that because it's all hogwash it's just
conting stories you know maybe it
happened this way maybe it happened that
way well there is a field of historical
Linguistics serious field but you can't
get away with it in that field by saying
maybe this happened or maybe that
happened you know and but that's almost
the whole field of what's called
evolution of language however there are
few things to say about it very few I
actually know of only two two things
that can be said about one is that
there's been it's it's of course
evolution of the language capacity it's
an evolution of humans language users
and one thing we can be quite confident
about is that nothing has happened for
at least 50,000
years whatever the date is from when
humans began leaving Africa small number
of humans started drifting out of East
Africa roughly 50 maybe 75,000 years ago
something there's archaeological
evidence about this and since that time
nothing's happen and you can be pretty
sure of that just from the fact that uh
infants today are equally capable of
acquiring any language without any
difficulty so they've all got the same
language capacity I mean there's there
are individual differences but I don't
think there are any group differences
known not everything's been studied of
course but the evidence on this is
pretty overwhelming so this strong
evidence that either nothing or nothing
of any significance has happened for
maybe 50 75,000 years uh the second
piece of evidence Which is less certain
but reasonable at least is that if you
go back
another uh say 50 or 75,000 years
there's no evidence archaeological P
anthropological evidence there was
anything like
language okay you don't get the
artifacts the complex symbolic
representations it all seems to have
come along pretty suddenly uh sometimes
called a Great Leap Forward by
paleoanthropologist roughly in that
window well that that's an extremely
narrow window from an evolutionary point
of view you know it's a flick of the eye
so what appears to have happened is that
something changed suddenly which yielded
this
capacity and notice that there were no
selectional effects at that time things
that change are happen to an individual
like a group doesn't undergo a rewiring
of the brain or genetic uh alteration or
something an individual does and that
individual is under no selectional
pressures zero I mean the capacity could
proliferate through a small breeding
Group which is what our ancestors were
and maybe after a while you know a lot
of people have it and at that point it
would make some sense to figure out a
way to make it public it's all going on
in the head that that's
externalization externalization is a
tough problem it's a tough cognitive
problem you have to match whatever's in
the brain which got there somehow
probably like you know some small
rewiring you've got to match that with a
sensory motor system which had been
around for hundreds of thousands of
years and for that there's good fossil
evidence so there's a sensor and maybe
as far back as chimpanzees you know Pro
many years ago but 6 milon years ago but
uh the U you've got to match these two
different systems which have nothing to
do with each other and that's a pretty
complex process which can be done in a
lot of different ways there be a lot of
ways of mapping something that sort of
satisfies the strong minimalist thesis
to A A system that has AB nothing to do
with it and in fact we just know you
know that the overwhelming complexity of
what we observe in language
overwhelmingly the complexities in the
externalization of course you know maybe
we just don't know other things about
what's internal but uh the vast
complexity looks like it's in the
externalization also the diversity I
mean that's where languages seem very
diverse on the surface but the more you
look you find they're much less diverse
at the computational level the eye
language level which makes and they're
also very easily subject to change at
the externalization level I mean it's
happening every generation you know
teenage jargon so Norman Invasion
changes the externalization massively
and it's the whole history of language
not Evolution but change uh so it looks
as though just from data like these that
uh the externalization
pro aspect of language is some ancillary
phenomenon it's kind of tacked on
after something developed which had no
selectional pressures so therefore it
would have been optimal it would have
been something like a snowflake it just
happens by laws of nature well that's
the strong minimalist thesis that there
ought to be a snowflake in there which
is mapped onto the sensory motor system
by a lot of different complex ways which
can be rediscovered and changed and be
modified and so on but it may not even
be part of eye language in the kind of a
narrow sense maybe it is maybe it isn't
there's questions about it but anyhow
it's kind of ancillary now much more
interestingly there's linguistic
internal linguistic evidence that leads
to the same conclusion and that's much
more interesting because these are all
you know speculations based on the two
or three facts we know about language
Evolution the internal evidence is much
more significant and that comes right
away as soon as you look at the most
Elementary combinatorial operation merge
so go back to merge it's
uh kind of no hypothesis is it doesn't
change the things that are emerged and
it doesn't impose order okay uh just
take the first of those doesn't change
the things that's merged uh well just by
the logic of the situation nothing else
if you look at merge of XY it has two
possibilities EX actly two one of them
is called external merge the other's
called internal merge and by just logic
nothing to debate those two are
available and uh uh they have a definite
output uh external merge is essentially
what puts things together and leaves
them as a unit so you take whatever
underlies uh you know the man and
whatever underlies uh
uh is tall and you put them together you
get something that underlies the man is
tall okay external merge internal merge
which is the only other possibility
takes some unit let's say uh you know
red the book and take something that's
inside that unit and merges it to it so
the book read the book or what the man
saw what you know okay that's internal
merge now notice that that has two
properties for one thing it yields the
displacement displacement is a
ubiquitous property of language you see
it all over the place the other is it
yields the copy Theory they both remain
okay that's the null hypothesis there's
a lot of confused literature about the
copy Theory assuming it involves other
operations you know copy remerge and so
on no nothing it's just the most
Elementary case of merge if it doesn't
occur in some language you got to
explain why so you need some stipulation
to block it okay because it's just
free uh now that's important for a
number of reasons for one thing those of
you know the lyri RO know about this and
those of you who work on it that the
copy theory has extremely important
consequences at the CI level conceptual
intentional level it yields most of the
basic reconstruction of effects
automatically now that's quite
significant these are very complex
sematic effects I won't go into them you
know about them they're very complex
sematic judgments and it's extremely
mysterious where they come from a child
has no evidence for them zero but
everybody knows them and they know them
in a very specific way so it's got to
follow that they just come from some
Elementary mechanisms is there anyhow
and yields these results
now we it doesn't yield all of them and
that suggests a research topic show that
it yields all of them because it ought
to and if it seems that it's not
yielding all of them there's something
we don't understand about reconstruction
processes and you should important topic
of inquiry is fill in the Gap uh show
that in fact if we understood everything
yeah it would yield all of close enough
to make that plausible and it's
conceptually natural because it ought to
you know uh the second fact about it I'm
sorry the second important fact about it
is that it yields it produces the major
complications in parsing communication
those of you who've worked on parsing
programs are aware that the toughest
problem is what are called filler Gap
problems okay so you you hear a sentence
with a wh phrase at the beginning you
got to figure out where it comes from
well why does that happen well let's go
back to the principle of minimal
computation as least computation as
possible what that's going to do is give
you the copy Theory internally and it's
going to wipe out all copies except at
least one because everyone you have to
have at least at least one or you don't
know anything's happened but uh it has
to wipe out all the others CU that each
other copy and there can be many copies
you know it's not as simple as what did
John see you look at more complicated
sentences copies all over the place uh
has to WIP each one of those copies is
complicated to compute and to articulate
and they can be of arbitrary complexity
remember each of these phrases can be of
arbitrary complexity so if you pronounce
all the copies it would overcome almost
all of the filler Gap problems but it's
a lot of extensive computation so what
you have is a conflict between
computational efficiency and
communicative efficiency it's one of
many such conflicts and in every case I
know correct me if I'm wrong uh
computational efficiency wins hands down
there's never even any competition
everything works by computational
efficiency doesn't give a damn what the
effects are for communicative efficiency
and that shows up all over the place I
mean take just ambiguous structurally
ambiguous sentences you know flying
planes can be dangerous uh they come
about if the rules just apply with
nobody fiddling with them but they cause
communicative problems got of or or uh
what are they called Garden Path
sentences another example or probably
Islands I mean islands are basically
things that you can think but you can't
say you know you have to find some
paraphrase and to the extent it's an
interesting topic trying to understand
them but to the extent that they're
understood which is limited they seem to
follow by making optimal rules and
there's another Gap try to show that
it's always the case if it's all always
the case as it should be then there'll
be another case at that point Point
well another example which is
interesting because of its history and
its consequences and because it's been
very intensively studied is a structure
dependence that was noticed as a puzzle
back in the 50s it was never regarded as
a puzzle in the preceding several
thousand years of intensive language
study but if you take a sentence like uh
instinctively uh Eagles that fly swim
very simple sentence uh instinctively
goes with swim it doesn't go with
fly okay no one ever makes a mistake
about that the children never make
mistakes about it uh there's no a lot of
the discussion of this has been confused
by the fact that the examples that are
looked at involve displacement it's
irrel and so people have all kind of
complicated theories about displacement
but it doesn't matter you have exact ex
actly the same Phenomenon with no
displacement and it's furthermore every
construction that's the fact of it is
that there's a simple computation linear
computation the simplest possible which
would get instinctively to link up with
fly instinctively equals the fly swim
it's the closest just count okay so it's
the closest easiest computation you can
get never used uh the
the actual computation is much more
complex it involves structure uh it
involves minimal structural distance
it's a much harder uh computation and
that's done in these constructions in
fact it's done in every Construction in
every language that has any of these
properties so there's got to be some
reason for it uh and a very simple
reason would be that there's no linear
order that at the point where all this
stuff is being computed internally
there's no linear order so therefore you
have to use the next most complicated
minimal distance measure structural
distance now that would yield a whole
mass of results in all kind of languages
no exception known but of course it
requires assuming that the merge
operation is
unordered that is that we have something
like a strong minimal thesis now this
one is kind of interesting because just
modern history there's a small industry
in computational cognitive science it's
even gotten into the linguistic
literature whole issues of linguistic
journals devoted to pointless proposals
about this as you guys know uh trying to
show that you can get it somehow some
other way you know statistical analysis
U couple of examples in the Wall Street
Journal I mean all kind of crazy
proposals are given there are
interesting because they can be
investigated they're clear enough to be
investigated so you can easily
demonstrate that everyone is not only a
failure but an IR remediable failure
there's no way to get out of it you know
uh and uh yet they keep coming uh
because it's just not permitted that
there be a linguistic principle of ug in
fact that would account for a huge
complex massive phenomena a kind of
interesting pathology in the field you
can try to explain it but it's a very
interesting principle simple one it's
rooted in has a conceptually natural
base and it does suggest that uh order
is just a reflex of the sensory motor
system well primeasia that doesn't look
possible it conflicts with a lot of
important linguistic work primeasia so
what we want to ask is does it really
conflict I think the most striking
complex conflict perhaps is with the
work on what's called cartography you
chinku REI others so say take U chink's
what he calls Universal base hypothesis
you
know mood tense verb object that kind of
thing and plus a lot of refinement you
know extensive refinement of these
categories with dozens of uh postul
functional categories in his system
which are ordered in a particular way
well this seems to conflict with it
because that all enters into semantic
interpretation however uh these studies
which are extremely interesting and the
uh empirical work is very impressive I
think but it just can't be right you
know there's no way in which anyone
could possibly learn that functional
structure I mean incon conceivable
there's no evidence for it you know and
although it could develop through an
evolutionary process it's pretty hard to
imagine how I mean why should Evolution
ever give this crazy thing why not
reordering them somehow so the natural
assumption and I think chenwick kind of
agrees with this we've talked about it a
lot is that and Luigi Rey also that
there ought to be
some sematic or pragmatic reasons why
they come out this way and not some
other way you know and there's some work
a couple of dissertation some other work
trying to work it out well there's a
good reason to expect that that's where
it's going to go if we learn enough so
another Gap to look at but if it does
then this work well you know I'm not
questioning its significance I think
it's very significant probably won't
have to do with language eye language if
you can reduce some observed phenomenon
to a pragmatic consideration let's say
like it wouldn't be useful to do it the
other way uh as there's an extraneous
Source you know outside the ey language
system and of course there's plenty of
interaction of all kinds of things so I
think that's a direction to look
important direction to look uh anyhow
what all of this seems to me to suggest
is that we abandon a contemporary Dogma
And I stress contemporary very modern
Dogma that the core of language is
communication that's the last 50 years
if you go back before that the
traditional view was that language is an
expression of thought and that goes all
the way back you get it in linguists
like William Dwight Whitney uh uh decart
Galileo you know Aristo everybody
language is supposed to be an expression
of thought today it is literally a Dogma
that it has to be based on communication
like in the philosophical literature
there are articles by good people was
saying I can't who can't understand how
I can even question this since it's kind
of it's like the nose on your face it's
got to be true well there strong
evidence that is isn't true of the kind
that I mentioned but that doesn't matter
it's got to be true why well interesting
question but my my suspicion is that
it's a consequence of the uh Behavioral
Science dogmas of 50 years ago
which covered the whole field you know
the whole range of fields Linguistics
psychology philosophy and so on you had
to believe in them and if you believe
that then it's natural to think that
that communication would somehow be the
core of language I suspect it's also
based on total misunderstanding of
evolutionary biology which is very
common among the people who talk about
it not not evolutionary biologists but
anyone who alludes to it uh that's the
belief that there is a phrase in Darwin
it's there uh which crucially there you
know right in front which says uh
evolution has to be the result of small
changes you know accumulation of a lot
of small changes that gives you uh
different uh organisms his book of
course was called Origin of Species but
you notice there's nothing about species
in it because there's even today it's
extremely unclear how species develop
but the evidence by now it's quite well
known
that no one's questioning Darwin's
insights yeah of course natural
selection is significant but it's very
well known that that's just not true
there's case after case of dramatic
change probably involving species
appearance which is sudden from an
evolutionary point of view so for
example classic example just not certain
but it's widely assumed by evolutionary
biologists is the change from
invertebrates to primitive vertebrates
cordat seems to have come from a tiny
change which all of a sudden changed the
whole body plan and everything else and
there's plenty of other cases so there's
no reason to believe it you know it's
not in accord with evolutionary biology
it's a Doctrine you learn it in 8th
grade and so on but you put it out of
your head uh if you believe it then it
makes sense to trace language back to
communication because you get
communication you know all the way back
to bacteria so every organism has some
way of communicating interacting with
the environment or each other and you
can make up a story which is or a
thousand stories they're all each is as
good as the other uh about how maybe
small changes in communicative practice
led the language you can't make up any
story about how eye language developed
by small changes because that's a sudden
change it's a new principle new
phenomenon had to be a kind of rewiring
of the brain maybe a small genetic
change nobody knows enough to say but
it's very hard to even imagine a
plausible alternative but apart from
General
plausibility uh there is H there's very
strong evidence most of it internal
linguistic evidence so therefore nobody
looks at it because one of the
principles of cognitive science these
days is you're not supposed to know
anything anything it's kind of crucial
not to know anything literally uh like
my own University if a student in the
cognitive science department has a
thesis on or an article on language
which involves knowing something about
language it's almost automatically
thrown out uh and that covers a lot of
the field and I think there's an origin
for that too it comes back to uh the
early days of artificial int
intelligence it's deeply rooted in the
computational cognitive Sciences you're
not supposed to understand anything
because the principle is if you have
huge mass of data and you throw a big
computer at it and you have a lot of uh
statistics something's supposed to come
out well chances of that happening are
approximately zero and if you look at 60
years of it I think the results conform
to the expectations uh but if you
adopt that way of looking at things and
if you're kind of you got in the back of
your mind the whole Behavioral Science
framework uh it sort of these
conclusions come out pretty naturally
but I I think they it's very it's kind
of important that people in the field
you know this field our field at Le what
I take to be my field is not going to
survive unless the surrounding
intellectual environment can see why
there's a point in carrying it
out and uh to a very large extent that's
not the case and it's diminishing which
is a problem for those of you who are
not my age you would to think about not
not a problem for me I won't be around
but uh well there are how we on
time minutes 35 minutes yeah we have
okay uh oh well I'll stop then okay I
there's a lot of stuff I want to get
into but uh why don't I stop and leave
it open actually you should have been
interrupting all along since you're too
polite then uh you know I can go on sort
of indefinitely
but
[Applause]
yeah yeah
okay uh from the
uh logic that you laid out here about
say Theory being simply result of no
tampering U would you have to say that
the interpretation of these kinds of
structures would have to be something
that is a third Factor kind of thing so
for example if you say you know what did
John see getting what did John see what
that's not what you're interpreting
right I think it is when you're
interpreting well then what is it it's a
very straightforward interpretation what
did John see what you can write it out
in classical logic I don't say that's
the way it's done but it's easy uh for
which x x a thing uh John saw the thing
X that's what you want to interpret but
that's not what the copy gives you no
but that's a way of anot see the as far
as the brain's concerning it may just
look at what did you see what okay we
can write out what it's doing in a way
intelligible to us because we
studied Elementary logic in which we
express it as for which thing X John saw
the thing X but there's no reason to
believe that's what's going on in here
it may be just looking at what John saw
what and interpreting that
way I don't know U there certainly are
theories out there
what what it is that has to be
interpreted on the basis of that input
so like Danny Fox a particular Theory
yeah these are all notice there's a lot
of ways of saying it yeah but they're
all saying the same thing they're saying
we've get this thing what John saw what
and we're asking what's a natural way of
putting it in terms that we understand
now I don't say that these are just
arbitrary choices like the different
choices say foxes and someone else
sometimes have empirical differences but
not often if you look they're usually
inter
transable so you can do with I think
there are differences pardon I think
there are differences in how yeah if
there are differences fine then you look
at them and that gives you more insight
into exactly how it's being interpreted
but notice that what we're looking at
we're looking at the rules that are
called formal
sematics okay these are generally
understood to be operation s that take
the narrow syntactic objects like what
did you see what and turn it into
something interpretable at
CI okay but then we're back to the
question I asked before let's say there
are differences among the different
approaches I don't think it's all that
obvious but let's say there are then
then there's a right answer and a wrong
answer okay there's a right mechanism
and a wrong one where is that mechanism
is it in the eye language or is it in
the thought system well we don't know
but uh okay so there's some mechanism be
interesting to find it and then we'd
have to explain it but if you take that
I stop this but if you take that view
then then you also attribute a lot to
the thought system not not attributing
it just say we don't know I mean it
doesn't you know there's no more
complexity assuming it's attributing to
one than the other I mean first thing
you have to show is that there are
empirically significant differences
between
different ways of interpreting what the
narrow syntax gives you it's not a
simple task as you know but suppose you
can if you can then you have an argument
for one mechanism over another mechanism
next question where's that mechanism in
the whole architecture of
cognition uh third question why is it
there well maybe the reason why it's
there is some third Factor principle we
don't know
but since these since we don't have a
theory of computation that holds For
Thought systems or sematic
interpretation you can't talk about uh
third Factor principles this is very
much like Naros syntax in the
1950s you postulate whatever mechanism
you need you know T markers or whatever
it may be to give you some
phenomenon and that just can't be right
for the same reason it wasn't right in
Naros syntax so you have to ask okay why
is it this way not some other way in
other words you have to pursue the
minoff program you have to and that you
I'm not criticizing it but it hasn't
even been undertaken in these
domains the all the work you know maybe
rightly is devoted to how to get
mechanisms which will give you the
descriptively accurate results okay
and that's fine I'm not I don't mean to
be critical like I wasn't critical of
the work in the 50s and narrow syex but
it's just the beginning you know you got
to go on and answer all these other
questions it's kind of like cartography
I think extremely interesting work
raises all kind of questions okay go on
to pursue the question and I think these
are the questions that arise in this
case for all of formal semantics notice
that formal semantics is not semantics
it's misnamed it's
syntax formal sematics is symbol
manipulation by definition that's syntax
you know the classical Notions of you
know syntax matics pragmatics are a
simple manipulation of syntax and then
there question where it's going on and
sematics has to do with relations to
some outside world okay and it's very
possible in fact my view correct
probably that language doesn't have a
sematics I mean we talk about the
outside world but that's referring or
talking about those are actions from the
fact that we refer to things which we
certainly do it doesn't mean that
there's a reference relation in language
and I think there strong evidence there
isn't there is in animal communication
as far as we know so it looks as though
in animal communic one of the many
respects in which animal communication
systems look to totally different from
human language in almost every respect
but one of them is uh actually Randy
gist's worked on this among others that
uh it seems to be the case in animal
communication systems that every symbol
has a one toone relation to some
externally
identifiable physical phenomenon so you
know the leaves flutter and the veret
monkey eliminates El emits what we call
warning coal or some hormonal change and
elicits what we call I'm hungry you know
and that looks first of all it looks
reflexive like they got to do it and uh
it also seems to have a denotational
property you know there's a mind
independent
characterization of some event in the
world that's one to one related to the
internal symbol the human words are not
like that at all this the denotational
Dogma that claims that words nouns refer
to things you know verbs to events and
so on since you look at the words they
don't do that at all I mean any word
that's ever been looked at doesn't work
like that it's perfectly true that we
refer to things but not that way it
looks like part of the theory of action
and if that's correct language doesn't
even want to have
atics it'll have an internal syntax and
a
pragmatics uh
I'm not saying you can prove this but uh
at least my view is that's what the
evidence points to but the in the work
that you're talking about which is quite
fascinating you no integration is
syntactic work by definition that's true
inly all of model theoretic
semantics model theoretic semantics for
those of you who work on it postulates
individuals and studies Arrangements of
the individuals predicates over the
individuals and so on but the
individuals are mental
objects they're not things in the
world uh there anything you postulate to
make the mechanisms work and you somehow
have to relate all this stuff to the
world well at that point you're getting
into sematics but nobody looks at that
and in fact if you do look at it I I
don't think there's any way to do it uh
it's not that the models are wrong it's
just that to find a way of showing how
they enter into the acts of referring is
going to be a tricky thing it's not just
you see a cow and you say cow no do that
doesn't work at
all what's the difference between an
algorithm and a generative
process well you can take a mar again a
generative process can be studied at any
of his three levels actually only well
let's take an input output so General
process are different but take what he's
talking about say Vision so you can
study Vision which was his Topic at all
three levels you can say at the
computational level the problem of
vision is uh take a real case uh you
have uh three dots on a tachistoscopic
image and you have a series of these
three dots okay that's the external part
the internal part is you see a rigid
object in motion
a pretty crazy thing but it's true it's
called the rigidity principle so uh the
computational problem is to is just what
I said you get a series of three dots on
a pistos scope you see uh a rigid object
in motion that's the computational part
then comes the algorithmic part figure
out the right mechanism the right
procedure that will map one into the
other
okay then and you got to get the right
one because could be others The Next
Step would be what's going on in the
visual cortext that implements this
algorithm so you got all three when you
look at a generative process you only
have
two uh there's an internal process maybe
the kind I described maybe something
else which is yielding these structures
it's not forming them I mean that's kind
of like think say if you're studying
mathematics you think of a function I
mean the way you kind of intuitively
think about it is the function is taking
this and it's yielding that but a
function is just a relation it's not
doing anything you know it's just saying
here's a relation you know that's a kind
of intuitive way of thinking about it
but or take a proof you study let say
logic and you learn what a proof is you
take the axioms apply the rules of
inference and ultimately you get the
theorem that's nothing to do with proofs
I that defines geometrical object a
proof is a geometrical object it's a
certain geometrical object and the Axiom
system determines the infinite set of
those uh geometrical objects but proving
a theorem is nothing like that I the way
you prove a theorem is you got something
you think may be true you know try to
figure out a LMA maybe it follows from
this and see if you can establish the
lemon and then do some other crazy thing
what you know get flash of insight
whatever it may be that's proving a
theorem but a proof itself though it's
described as if it's an action isn't
just as a function isn't an action or a
rule of multiplication is not an action
it's just saying here's the triple such
that xal y * Z you know just listing
them and that's what gous process is so
there aren't any
algorithms there's there's a
computational account and can say here's
what it's doing somewhere which we don't
know there's some mechanisms that are
going on but there's no middle
level that's why the applications of
Dave Mars very interesting and valuable
approach just don't work for gener
processes um the hysteria aside you
think there's a role that statistical
models models bu
observational Communications data like
the newspaper there's a ro for those mod
like give you a personal anecdote if you
don't mind uh when I got my degree PhD
which was a total fraud incidentally I
hadn't done any work or anything else
and I won't go into why it happened but
I had no professional qualifications at
all and that's why I went to MIT because
they didn't care but and they didn't
care because they get a ton of Pentagon
money pour it in to do research and do
whatever you like but that's how a lot
of us got by but uh I was I was talked
to the director of the lab and he listen
he was interest he was a scientist you
know I told him I was working on sounded
kind of interesting so he asked me if I
wanted to work on a machine translation
project that they had and I said that's
a stupid project I'm not going to work
on it but if you want to hire me under
the project that's fine and then I'll do
the work that I'm talking about he
thought that was a prettyy good answer
so I got the job luckily but I I don't
suggest that as an approach but work in
this case the reason why I was stupid
project is linguistics is nowhere near
enough to give a principle to answer to
how you might do something like that so
if you want to get it done do it by
Brute Force you know take uh Canada well
what they actually do by now after
having given up in linguistics properly
they take the Canadian Ian Hansard
parliamentary records they're in French
and English parallel so do a ton of
totally boring and irrelevant
statistical analysis and you can kind of
get an approximation to which French
phrases and which English phrases more
or less go together that's how the
translation the Google translation
programs work they just match up a lot
of garbage and do some techniques that
don't give any insight and it'll it's
like building a bigger bulldozzer
there's nothing wrong with big
bulldozers but you don't study Physics
that way uh so sure it's fine there's a
lot of things you can do that way in
fact almost anything in areas that you
don't understand are done that way I
mean almost all of engineering was done
that way up until a generation ago like
when I got to
MIT main engineering school in the world
there were very good math and physics
departments but they were service
departments they were just teaching
Engineers
tricks uh and if you if you wanted to
build something you would go to MIT you
learn how to construct an electric
circuit or build a bridge or something
okay go MIT it's mostly brute force and
uh you know lore things that people have
learned by
practice the physics and math kind of
help out to sort of formulate things
things within 10 years it had totally
changed by the 1960s when you guys were
there or later it was a science
university uh anyone who no matter what
engineering profession you're interested
in you study the same basic science and
then maybe some applications to
different areas and the reasons are
simple for the first time science really
had a lot to tell engineering and
furthermore technology started changing
very fast there was any point learning
how to design an electric circuit if 10
years later it's all going to be done on
a computer you know and the same with
every other field so that's it's very
recent notice it's very recent that
science had much to tell
engineering same with medicine I mean
until practically the last generation in
fact is a famous line in the history of
medicine that uh I think I forget what
year maybe in 1920 was a critical year
in the history of medicine because it's
the first time uh when if there was a
confrontation between a patient and a
doctor the patient might improve from
it and the reason primarily was
chemistry and Engineering so you get
drugs that really cure things and you
know people can fix your broken bones
and stuff like that uh but um almost all
medicine is is still just
lore now good doctors or nurses and
others kind of know from experience
intuition wherever it's coming from that
this is a way to deal with this problem
sometimes right sometimes wrong but
science is finally contributing
something and you know Linguistics is
nowhere near physics and biology I mean
we don't understand the most Elementary
thing and machine translation is much
more complex than curing pneumonia or
something so there's a huge gap and in
that Gap these statistical models are
fine they're Brute Force methods don't
yield any insight or understanding
except in the way that Charles does it
when you integrate it with ug principles
uh which gives you something you know uh
and I think that makes sense there
shouldn't be any conflict about it but a
lot of people are pretty hysterical
about it I don't know if you read Peter
norvig's
diet dribe the guy who runs Google and
went crazy and he gave a lot of examples
which are right those are examples of
brute force in areas where you don't
understand anything and so yeah you go
by Brute Force because you don't
understand yeah know I was asking about
the other way whether statistical models
can help answer deep questions about
language sounds
like that's I don't well you know a lot
more about an I do but uh see I'm
interested in seeing what you think but
my feeling is that statistical
alone have a record of zero success is
that an
exaggeration
yeah at least I don't know the case nor
do I expect them to why should they I
they've got to be based on something you
know you don't if you're doing basian
models you start with priors where do
they come from you know if you look at
the literature on it
say famous very well-known study about
by colleague of mine Joshua Tenon bound
on in came out in science on how to grow
a mind or something you know that paper
he starts by postulating the priors for
and the priors are kind of a network of
Concepts which answers all possible
questions before you start except that
the concepts are all wrong and then he
does a lot of U complex statistical
analysis and ends up saying well there
isn't much to say say about this that's
considered a major contribution if
that's if you think that's a caricature
read the paper but a lot of the stuff in
the field is like that and it's what you
expect I mean if say you wouldn't study
Physics by taking a ton of videotapes of
what's happening outside the window and
uh doing complex statistical analysis of
it I me you might get a pretty good
prediction about what's likely to be
outside the window tomorrow in fact way
better than the physics department can
give you
but it's not physics I think one of the
best ways of predicting the weather in
Boston I learned years ago is to read
the Cleveland
newspapers we usually get their weather
the next day okay it kind of works
probably as good as
meteorology but it's
different
yeah I'm interested in this idea about
uh first there was this brain event or
something that led to langu
use in thought but not in
communication and and furthermore it's
when it got to communication
that well that's the thing I'm wondering
is that when you got ordering was did
you get ordering in
thought before that we don't know
whether there's ordering in thought
because the only introspection we
have is into internal external
language so if you just introspect you
can't go a minute without talking to
yourself but you're talking to yourself
in externalized language what's going on
inside well that's not accessible to
Consciousness but if you introspect
about the process there hasn't been much
work about that so let's talk my
personal introspections my impression is
that when I try to say something even to
myself
if something is there first I mean I
know what I mean and I try to say it and
it doesn't come out right and you try
something else and maybe that gets
closer and uh sometimes you find you
just can't express it you know you can't
find a way to express it that captures
what you're thinking uh that kind of
experience and there's a lot actually
there's some experimental work that's
like it that bears on it seems to
indicate that probably everything of any
in significance is going on Beyond
Consciousness the experimental work has
to do with the choice the libid
experiments which I think have been
badly misinterpreted but
uh there are some experiments that show
that if I uh intend to pick up a cup say
um milliseconds before I intend there's
something going on in the uh you know
motor organization system okay that's
been argued to show you don't have free
will it doesn't show anything it just
shows that it's all the decisions are
all going on
unconsciously and by the time they read
Consciousness which sometimes happens
sometimes doesn't this kind of
peripheral phenomenon uh it's all done
and that's probably true of everything
now studying unconscious thought is no
trivial matter I mean it's it's not
impossible so for example there have
been studies of um
there have been studies of uh somebody
you will know the details of people who
are just
thinking just thinking about things to
say it turns out you can detect a very
slight lip movements and things like
that now I've asked some people who work
on
sign and there some people are looking
at it to see if when people are thinking
in first of all nobody knows how people
are thinking in sign it just hasn't been
investigated like take a a a native
speaker of sign language I mean they're
obviously thinking all the time just
like we are are they thinking in sign
well if they are what what's it like and
can you detect uh hand movements minimal
hand movements well you know you could
pursue inquiries like this would give
you something but they're not going to
go very far because what's going on
beyond the level of Consciousness is
probably almost everything
significant that Consciousness is some
kind of peripheral thing which picks up
some of what's going on in our
head not a small problem you know but we
shouldn't pretend it's not there because
we don't understand
anything so we think in language but not
we don't know we don't know what we're
we don't know that we're thinking in
language which comes to Consciousness
first of all at least me when I
interspect into my use of language it
isn't sentences it's scattered
phrases know bits and pieces of phrases
I mean I can restate them as as a
sentence but when I really think about
it I'm getting you know a word here
another word there somehow it's all the
listening something that's really back
there somewhere and you put it together
try it sometime it's kind of interesting
to introspect into what you're doing
when you're just talking to yourself
we're not talking to oursel in something
you'd
write or even something you'd speak and
it gives the impression at least to me
as if something going on in there that
bits and Pieces come out occasionally
and we kind of construct them and try to
put them in a intelligible form and when
you speak or when you write it's another
step to trying to do it so but you know
this just guesses nobody's really
studied
it yeah um I I want to get back to your
first principles and I I I think you
might be hard pressed to find people who
wouldn't agree that there's something
about humans that gives us the capacity
for language there have to be some kind
of biases that help in statistical
learning or I'll give you some names if
you want Michael tomasel for example
look what he says is shared
intentionality he doesn't say anything
about principles of computation right so
that's what I wanted to ask you about I
wanted to ask you about and shared
intentionality is totally irrelevant
totally because people very well in
autistic children it correlates very
well with their UL attainment in
language their abilities in join
attention no that's different that's use
of language but you can have an autistic
child in fact knows them who have no
idea what anybody else wants and can't
deal with anyone else but whose language
is perfect and in fact if you look at
the just the AC acquisition
rate acquisition of language is very
early acquisition of what's called
theory of mind or something shared
intentionality that's considerably later
is that based on Ouija board kind of
yeah and any kind of experimentation
that's done I mean it's you know three
or four year olds that are picking up
the ability to do this theory of mind
experiments but there's a much more
serious problem even if we believe it
exists suppose it's based on shared
intentionality as he claims how do you
go from shared intentionality to
structure
dependence know or anything well there's
also categorization in grouping yeah but
categorization is a different thing
that's a thought process that's not
language I mean if it shows up in
language so this is what I wanted to ask
you about you you had said there were
clear dissociations between General
cognition and language abilities and I
wanted to know what those
were read the people write about it like
Susan Curtis has extensive work on any
kind of dissociation you can think of
but those have mostly been debunked as
far as so people have thought William
syndrome was a disassoc she's not
talking about that she's talking about
no she's talking about normal language
use uh well and in fact the there people
with normal language use who have all
kind of other incapacities and
conversely well that's what I'm talking
about but like what like William
syndrome turns out not to be the case
they don't learn language until they're
fully until they're 14 which gives them
a cognitive age of seven yeah so there
are cases where it's not true there are
cases where it is true it's the cases
where it is true that are interesting
can you name one H can you name one yeah
to take a look at her articles I mean I
just gave you one autistic kids whose
language is perfect and have no sense of
shared
intentionality and you know some of them
have say fantastic arithmetical ability
and no language yeah well okay that's uh
you know it goes almost any way you
look and there's plenty of studies of So
You Think autistic kids have the perfect
language despite no of course autistic
as you I'm sure you know is not a
category it's some kind of spectrum
that's not understood so there what we
call autism is all kind of different
things but there are children who are
diagnosed as autistic whatever that
means in fact I know some who have
uh the language capacity is essentially
perfect you can't maybe with some
complicated experiments you could show
something they don't know and they have
no conception of how to deal with anyone
else they can't get along with anyone
you know okay and it works the other way
there are people who kids who get a long
fine with everyone and don't
speak and there's every other kind of
dissociation you
like well I think the literature is
pretty strong on this okay whatever you
think but even if there weren't
dissociation Suppose there were none
still the proposals that say Thomas Ella
is making are completely vacuous because
there is no way to get from shared
intentionality or culture whatever that
is uh to anything simple that you think
of say U you know U structure dependence
to take the simplest thing in fact if
you look at the work pretty specific
accounts of structure dep he has zero
his account is uh somehow we know
subject predicate because of this and
that the other thing so therefore we use
structure dependent rules which doesn't
have anything to do with the question I
mean you can have
a lot of the cognitive computational
cognitive science work makes exactly the
same mistake they say look we have a way
of getting hierarchy that shows use
structure dependence doesn't show a
thing you can have hierarchy in fact you
must have hierarchy still leaves the
option of two methods of relating say
instinctively to a verb in the case that
I mentioned one is linear order that's
available the other is uh minimal
structural distance the fact that you
have hierarchy didn't tell you what you
get you have a linear order too so why
don't you use that one I this work is
just totally irrelevant it doesn't think
through the most Elementary questions
like both of those options are there
whether they have hierarchy or not and
say Thomas ell was right in his kind of
speculation that somehow you know
subject and somehow you know predicate
right grant him that tells you nothing
about why you don't use the linear order
nothing doesn't even raise the question
and the same is true on every other
property of language find one that isn't
well people like enough have argued that
you do use the order people like Ray
Jack have argued that you do use linear
order not for things like this that's an
other in communication you sometimes do
like there's a you know the wh move and
let's say it's to the left and not to
the right okay that's linear order so
you look for reasons they're probably
pragmatic reasons uh Richie has a lot of
evidence about how Lydia order shows up
okay look at it but the idea that but it
just doesn't bear on any of these topics
it doesn't it Bears on various way I
mean language use is a very complicated
thing has all kind of things interacting
you can find some which involve you know
emphasis
Focus some cases of say affronting of
negation which change things furthermore
incidentally on this case there happens
to be direct and pretty interesting
neurophysiological evidence evidence
that you don't that you can't use linear
order in the core cases uh the work that
came out of the Milan group you know
that well the very interesting studies
that came out of a it's been replicated
a lot by now but about 10 years ago a
research group in Milan Andrea Moro is
the linguist involved and they did some
very straightforward experimental work
they took speakers of I think German and
gave them two kinds of nonsense language
one kind was modeled on some language
they didn't know but accorded with ug
the other involved extremely simple PR
computational principles that aren't
known in language like for example
negating a sentence by uh putting the
negative particle in the third word
position well the they were just
studying neural coret it turns out that
when they give them the ug
conforming nonsense you get the normal
activation in the language areas when
you give them the trivial computation
put the negation in the third word say
you get it's puzzle you know people can
solve it but different areas of the
brain are working in fact it's very
diffuse it's all over the brain it's
puzzle solving and there's some
experimental work that It's Tricky that
conforms to this you know uh uh Smith
and simply's work with
their you know Chris their uh sort of
language genius this is a guy who has
essentially no Cog very low cognitive
capacities they have to help him go
upstairs to because you know where to go
in the house where he lives almost
nothing but he learns language very
quickly actually turns out he learns
phology and morphology very quickly and
the Lexicon he learns those aspects of
language which he doesn't it looks as if
he's learning syntax and sematics but
you look closely probably not it's just
there you know but uh he he acquires
languages very fast um they try to teach
him and a group of normals a different
languages some of them were some
language neither of them knew okay Chris
acquired what looks like competence very
quickly he does it in no time memorizes
dictionary things like that the normals
had a problem you know sometimes they
finally solved the puzzle then they gave
them uh he gave they gave them nonsense
languages which did same as Mora did and
did not violate ug the ones that did
violate ug the normals treated it like
some language they never heard of they
finally got it as a puzzle that Chris
could do
nothing it's just because he can't solve
puzzles
okay there's that kind of evidence but I
think the evidence is very strong and
quite apart from the evidence the
evidence really doesn't matter because
there is no way to go from the kind of
things that say thomaso looks at to
anything about language it's just hand
waving you say okay you do it by
induction and analogy or you know
something else that's
nothing that's what I meant by saying
this stuff gives hand waving a bad name
I think it really does this try to work
it out that's pretty strong more
question
yeah you said that a perfect language
system would satisfy the interface
principles in the most optional optimal
Fashion Is there a way to operationalize
optimal optimal that well first of all I
would like to qualify that because of
what I said
later I think it should satisfy the
CI level
optimally because the sensory motor
system seems ancillary now it has to
satisfy that too probably optimally but
it's going to be quite complicated so
the question is fair question what does
optimally mean well you know we don't
have a perfect theory of computational
complexity computational complexity is
used in biology and fact physics all the
time without a perfect theory of it but
some ideas about it you know and the way
you refine these ideas is by seeing what
works and asking what does that tell you
about computational complexity so and
some of the ideas are quite simple for
example less is better than more okay
less computation is better than more
computation actually that's alone is
sufficient for everything I said uh uh
or or minimal search is better than deep
search because it requires more
complexity
uh the not what I call the no tampering
condition you know you don't mess with
the things you're merging is more
efficient than changing them that's any
theory of computations going to have
that property or uh eliminate copies on
the way to
externalization that gives you a massive
restriction of computation or to take
another case that I didn't
mention this kind of language internal
here but if you look at work on
displacement over the years it's been
assumed by me too that displacement is
somehow a
complex property as distinct from what I
call internal merge is something comp
complicated that you somehow have to
explain a way it's kind of an
imperfection of language an external
merge you know just putting two things
together is
straightforward actually it's the
opposite it turns out if you think about
about it external merge requires a lot
more computation than internal merge uh
technically external merge requires
searching the entire space of accessible
objects you know the whole lexicon the
whole workspace and big search program
uh and then you can put together C and
John you know internal merge is much
simpler you're looking at one object
you're picking what's technically a term
of it that's well-defined notion and
merging that to the whole object that's
straightforward uh but uh uh there's a
lot of literature arguing good linguists
that copies should be that internal
merge should be replaced by external
merge so take what did you see what okay
the argument is way you just generate
you see what and then you take what
which you've generated outside and
externally merge them that's a very bad
idea for a lot of reasons for one thing
it it it it requires for one thing it
requires a stipulation you have to block
internal Verge which is free that's like
blocking any other thing that comes free
second is it involves a huge amount of
computation every thing that's displaced
has to be independently generated and it
can be of arbitrary complexity and it
can be present innum arbitrarily many
times in the construction and you got to
do all that computation instead of doing
a very Elementary computation take a
term of an object and merge it now any
theory of computation is going to at
least meet that condition and I think
you General this is inly true in other
parts of biology so for example if you
look at say I don't know if you know
Chris chc's work on optimizing neural
networks uh he he done interesting work
showing that if take very simple
organisms like you know nematodes couple
hundred
neurons and you look at the W with the
wiring diagrams known you know you know
everything about how they're connected
you know nothing about what the damn
thing is doing but that's another
problem but uh he's shown I think pretty
convincingly that you can predict the
wiring
diagram by a principle of computation
which essentially is the same principle
that's used in building
transistors minimize wire
length because if you minimize total
wire length you get the neemod he argues
that may extend to the fact that
vertebrates have the brain at one end
not in the middle you know things like
that well that's good work but why that
principle of computation you could think
of others
well that's the way science works you
you try to find sensible
principles that make sense see if they
work uh you can ask well are there other
principles that don't work what's the
difference between them can I refine the
theory so it's a good question but I
think it's a research question and for
our purposes at least at this primitive
stage of language you studied are just
obvious properties of complexity work
like less is better than
more equate efficiency and
optimality the same thing the two words
for something we're searching for we're
searching for the general principle of
biology and maybe of natur of the
natural world that tries to make things
simple and you know that goes back to
the origin that's all of science so take
say Galileo I mean his you know the
principle that he proposed for the
sciences and that everybody follows
since is we have to believe that nature
is simple maybe because God made it that
way nature is simple and it's the task
of the scientist to prove it if you
can't prove it you're wrong and all of
the Sciences are based on this you know
you throw that out you're just
collecting data in fact you not
collecting data because even to collect
data requires prior assumptions about
what is data
so so it's just it's just it's asking a
good question but it's a general
question about the nature of human
inquiry and it does show up in cases
like this and sometimes you know
sometimes you might find real examples
like say with chiac is there another
mode of
computation with structure dependence is
there another mode and if you can find
alternative proposals about optimization
good then you search you try to dis
distinguish them on some other grounds
but it's a research question you can't
answer it a priority you can start with
reasonable a priority assumptions which
get you pretty far but you have to be
willing to question them later on
because they could be wrong but that's
just inquiry you know can't get around
those
problems okay thank you very much
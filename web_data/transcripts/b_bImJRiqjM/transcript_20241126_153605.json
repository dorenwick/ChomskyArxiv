{
  "video_id": "b_bImJRiqjM",
  "url": "https://www.youtube.com/watch?v=b_bImJRiqjM",
  "transcript": [
    {
      "text": "Let's do this! Let's talk about theory of\ncomputation and the Chomsky hierarchy.",
      "start": 0.03,
      "duration": 8.67
    },
    {
      "text": "So we've been talking about finite state\nmachines. Finite state machines are a",
      "start": 8.7,
      "duration": 5.069
    },
    {
      "text": "kind of abstraction of what a computer\nprogram does. If you think about them",
      "start": 13.769,
      "duration": 5.331
    },
    {
      "text": "going from state to state with a\ntransition, it's sort of similar to",
      "start": 19.1,
      "duration": 5.32
    },
    {
      "text": "saying: if something happens, then do\nsomething else, if I get this input then",
      "start": 24.42,
      "duration": 6.48
    },
    {
      "text": "perform this output. This finite state\nmachine is an abstraction of what a",
      "start": 30.9,
      "duration": 5.999
    },
    {
      "text": "computer program can do, and it is only\none type of abstraction. There's many",
      "start": 36.899,
      "duration": 6.0
    },
    {
      "text": "other ways to explain what computer\nprograms can perform on strings, the",
      "start": 42.899,
      "duration": 5.761
    },
    {
      "text": "kinds of operations they can perform. And\nwe call these formal grammars. The",
      "start": 48.66,
      "duration": 4.5
    },
    {
      "text": "Chomsky hierarchy is the description of\nthese grammars from most restrictive,",
      "start": 53.16,
      "duration": 5.01
    },
    {
      "text": "which is what we've been seeing so far\nfinite state machines, to most powerful",
      "start": 58.17,
      "duration": 4.5
    },
    {
      "text": "which is Turing machines which\nessentially can generalize to",
      "start": 62.67,
      "duration": 3.449
    },
    {
      "text": "performing any operation on a string.\nSome of these formal grammars are gonna",
      "start": 66.119,
      "duration": 6.451
    },
    {
      "text": "help us overcome the difficulties that\nwe've had. For example the fact that some",
      "start": 72.57,
      "duration": 5.33
    },
    {
      "text": "things in language have long-distance\ndependencies where two distant states",
      "start": 77.9,
      "duration": 5.4
    },
    {
      "text": "have to communicate with one another in\norder to work. They can help us overcome",
      "start": 83.31,
      "duration": 5.57
    },
    {
      "text": "the problems of recursion where our\nfinite state machine has to keep going",
      "start": 88.89,
      "duration": 4.979
    },
    {
      "text": "down and down and down and then remember\nthe path upwards and upwards and upwards",
      "start": 93.869,
      "duration": 4.441
    },
    {
      "text": "so that it goes down n times and then it\ncomes back up an equal n number of times.",
      "start": 98.31,
      "duration": 7.16
    },
    {
      "text": "Likewise they could help us with the\nproblem of context, where before you",
      "start": 105.47,
      "duration": 5.92
    },
    {
      "text": "apply a rule, you need to figure out what\nother symbols are around you, and",
      "start": 111.39,
      "duration": 5.24
    },
    {
      "text": "depending on those, you perform the rule\nin one way or the other.",
      "start": 116.63,
      "duration": 6.96
    },
    {
      "text": "So again finite state machines are just\none type of automaton and there's other",
      "start": 125.39,
      "duration": 6.7
    },
    {
      "text": "systems that are less restrictive and\nthey are here in the Chomsky hierarchy.",
      "start": 132.09,
      "duration": 4.55
    },
    {
      "text": "Type 3 is a regular grammar which is the\nkind of grammar that a finite state",
      "start": 136.64,
      "duration": 4.78
    },
    {
      "text": "machine can describe. And we have other\ntypes of grammars, context-free,",
      "start": 141.42,
      "duration": 4.91
    },
    {
      "text": "context-sensitive, and unrestricted or\ncomputationally enumerable. Let's look",
      "start": 146.33,
      "duration": 7.45
    },
    {
      "text": "at each one of them. A type 3 grammar or\nregular grammar is what we have been",
      "start": 153.78,
      "duration": 5.85
    },
    {
      "text": "seeing so far, a finite state machine is\na subtype of regular grammar. You can",
      "start": 159.63,
      "duration": 6.15
    },
    {
      "text": "have a rule that has one input where you\nhave one task that you want to perform:",
      "start": 165.78,
      "duration": 6.48
    },
    {
      "text": "create a sentence, you don't need to look\nat the sentence before or after to",
      "start": 172.26,
      "duration": 7.11
    },
    {
      "text": "perform the task. You only want to create\nthis sentence here and you create the",
      "start": 179.37,
      "duration": 6.9
    },
    {
      "text": "sentence by making the symbol a n times or\nhaving many symbols n times m times,",
      "start": 186.27,
      "duration": 9.78
    },
    {
      "text": "but there's no way for you to coordinate\nthat these two run at the same time. Each",
      "start": 196.05,
      "duration": 4.35
    },
    {
      "text": "state is independent of each other\nin how many times it executes. This is",
      "start": 200.4,
      "duration": 9.42
    },
    {
      "text": "the grammar of the basic structures that\nwe had so far like Jane eats pizza. One",
      "start": 209.82,
      "duration": 6.33
    },
    {
      "text": "noun for the subject, one verb and zero\nor more nouns for the direct object.",
      "start": 216.15,
      "duration": 4.76
    },
    {
      "text": "English sentences - in English sentences,\nthe number of nouns for the subject and",
      "start": 220.91,
      "duration": 5.77
    },
    {
      "text": "the number of nouns for the direct\nobjects are not connected. If you have",
      "start": 226.68,
      "duration": 4.32
    },
    {
      "text": "Jane Smith here, you do not need to have\ntwo words in the direct object. You - Jane",
      "start": 231.0,
      "duration": 6.51
    },
    {
      "text": "Smith eats pizza, where this is two and this\nis one, is a perfectly valid English",
      "start": 237.51,
      "duration": 5.16
    },
    {
      "text": "sentence. So this is a type of rule that\nwill be described through a regular grammar.",
      "start": 242.67,
      "duration": 7.33
    },
    {
      "text": "Let's look at a context-free grammar.\nThis is one where you have a single",
      "start": 251.78,
      "duration": 5.769
    },
    {
      "text": "variable going in: you know you want - you\nwant to generate a sentence and then the",
      "start": 257.549,
      "duration": 4.861
    },
    {
      "text": "output or the right side of the rule can\nbe anything. You can have more than one",
      "start": 262.41,
      "duration": 5.189
    },
    {
      "text": "symbol. These symbols can coordinate how\nmany times you run them but then you",
      "start": 267.599,
      "duration": 6.301
    },
    {
      "text": "would need to program something to help\nthem remember. It can be a variable",
      "start": 273.9,
      "duration": 5.31
    },
    {
      "text": "somewhere that remembers that n is equal\nto 3, it can be a data structure like a",
      "start": 279.21,
      "duration": 6.63
    },
    {
      "text": "push down stack where if you push a n\ntimes then you know you have to pop a n",
      "start": 285.84,
      "duration": 7.41
    },
    {
      "text": "times and so the popping could be that\nthe number of times you're on b so if",
      "start": 293.25,
      "duration": 6.15
    },
    {
      "text": "you pop a 1-2-3, and then - I'm sorry if\nyou push them one two three and then you",
      "start": 299.4,
      "duration": 5.31
    },
    {
      "text": "know you have to pop them one two three.\nThis could be the number of times you",
      "start": 304.71,
      "duration": 3.42
    },
    {
      "text": "have b, b b b. So as you can see,\nyou can implement memory with a",
      "start": 308.13,
      "duration": 6.48
    },
    {
      "text": "structure like a push down stack, you\ncould implement it with a variable.",
      "start": 314.61,
      "duration": 4.01
    },
    {
      "text": "There's something that you have to do\nthat is additional to the description of",
      "start": 318.62,
      "duration": 5.32
    },
    {
      "text": "the states and their transitions. This is\nof course going to cost you",
      "start": 323.94,
      "duration": 5.61
    },
    {
      "text": "computationally. One rule that is a\ncont - that can be explained with a",
      "start": 329.55,
      "duration": 8.339
    },
    {
      "text": "context-free grammar is centered\nembedding. For example, the sentences like",
      "start": 337.889,
      "duration": 6.06
    },
    {
      "text": "The cat that I like eats tuna, where you\nhave a sentence like The cat eats tuna",
      "start": 343.949,
      "duration": 7.981
    },
    {
      "text": "and then the noun phrase can also have a\nsub sentence, The cat that I like eats",
      "start": 351.93,
      "duration": 7.97
    },
    {
      "text": "tuna, for example. In the final\nconfiguration you need cat cat I and",
      "start": 359.9,
      "duration": 9.519
    },
    {
      "text": "then like eats, so you need to push two\nnouns and then pop two verbs, or you can",
      "start": 369.419,
      "duration": 9.421
    },
    {
      "text": "just have a variable that remembers that\nn is equal to two and tracks that you",
      "start": 378.84,
      "duration": 4.74
    },
    {
      "text": "have two\ngoing in and two verbs going out. This is",
      "start": 383.58,
      "duration": 4.46
    },
    {
      "text": "a context-free grammar and again it's\ncontext-free because in order for you to",
      "start": 388.04,
      "duration": 5.58
    },
    {
      "text": "construct your sentence you do not need\nto look at previous sentences or at",
      "start": 393.62,
      "duration": 4.38
    },
    {
      "text": "following sentences. A type 1 grammar is\na context-sensitive grammar. In these",
      "start": 398.0,
      "duration": 9.45
    },
    {
      "text": "kinds of rules, you can have anything on\nthe left side and anything on the right",
      "start": 407.45,
      "duration": 5.4
    },
    {
      "text": "side, but you do need to have for every\ninput an output. For every time, for",
      "start": 412.85,
      "duration": 7.89
    },
    {
      "text": "every element like a to the n, you need\nto output something: it might be the same",
      "start": 420.74,
      "duration": 6.48
    },
    {
      "text": "or it might be different. For example in\nthe Yoruba emphatics, we had a rule that",
      "start": 427.22,
      "duration": 6.78
    },
    {
      "text": "took a vowel, a tone, and a consonant if\nit existed. For every vowel you had in",
      "start": 434.0,
      "duration": 6.69
    },
    {
      "text": "the input you, had to give - you have to\nproduce the vowel in the output. For",
      "start": 440.69,
      "duration": 6.18
    },
    {
      "text": "every consonant you had in the input you\nhave to bring the constant to the output,",
      "start": 446.87,
      "duration": 3.66
    },
    {
      "text": "but then for every tone in the input you\nhave to read it, you have to perform an",
      "start": 450.53,
      "duration": 4.59
    },
    {
      "text": "operation on it, and you have to give us\nan output. So there's a one-to-one",
      "start": 455.12,
      "duration": 4.17
    },
    {
      "text": "correspondence even if the output itself\nis different. We call it again",
      "start": 459.29,
      "duration": 7.62
    },
    {
      "text": "context-sensitive because in order for\nyou to know what def is, you need to",
      "start": 466.91,
      "duration": 6.03
    },
    {
      "text": "read some things about abc and in order\nfor you to know what abc - how abc",
      "start": 472.94,
      "duration": 7.71
    },
    {
      "text": "are going to interact, you need to\nactually look at them, to look at the",
      "start": 480.65,
      "duration": 3.15
    },
    {
      "text": "sounds before and after you. So regular\ngrammars are for example a basic English",
      "start": 483.8,
      "duration": 9.57
    },
    {
      "text": "sentence, context-free grammars are\ncenter embedding which is more complex,",
      "start": 493.37,
      "duration": 5.37
    },
    {
      "text": "and you need to coordinate things but\nyou still don't need to look at",
      "start": 498.74,
      "duration": 2.49
    },
    {
      "text": "sentences around you, a context-sensitive\ngrammar is one where you do need to look",
      "start": 501.23,
      "duration": 4.5
    },
    {
      "text": "at the sounds around you, like in Yoruba\ntones. And an unrestricted grammar or a",
      "start": 505.73,
      "duration": 5.82
    },
    {
      "text": "computationally enumerable grammar is\nanything else: one where you can have an",
      "start": 511.55,
      "duration": 5.35
    },
    {
      "text": "arbitrary number of symbols as the input\nand then produce some output that is not",
      "start": 516.9,
      "duration": 5.76
    },
    {
      "text": "necessarily matched to the input. Human\nlanguages probably don't have these",
      "start": 522.66,
      "duration": 5.49
    },
    {
      "text": "kinds of rules, but this is the kind of\nrule that have been handled by a Turing",
      "start": 528.15,
      "duration": 4.59
    },
    {
      "text": "machine. A Turing machine would take a\nstring - an input string of any kind and",
      "start": 532.74,
      "duration": 6.54
    },
    {
      "text": "an arbitrary number of symbols, and then\nit would transform it into some other",
      "start": 539.28,
      "duration": 4.65
    },
    {
      "text": "string with an arbitrary number of\nsymbols in the output. Of course the",
      "start": 543.93,
      "duration": 6.51
    },
    {
      "text": "problem with this is that this comes\nwith added computational power, we can",
      "start": 550.44,
      "duration": 4.65
    },
    {
      "text": "take any input and put it into any out -\nand convert it into any output but now",
      "start": 555.09,
      "duration": 5.01
    },
    {
      "text": "the cost is that not only is our\nprocessing going to skyrocket, we cannot",
      "start": 560.1,
      "duration": 5.73
    },
    {
      "text": "even guarantee that we're ever gonna\nstop the operation. More on this in the",
      "start": 565.83,
      "duration": 5.64
    },
    {
      "text": "next video. In summary we have four main\ntypes of grammars for the Chomsky",
      "start": 571.47,
      "duration": 7.38
    },
    {
      "text": "hierarchy: we have regular grammars which\ntake one input and have many outputs,",
      "start": 578.85,
      "duration": 6.24
    },
    {
      "text": "but these outputs are each of them\nindependent from the other, and yeah they",
      "start": 585.09,
      "duration": 6.3
    },
    {
      "text": "don't remember how the other behaved.\nThis is our syntax of sentences in",
      "start": 591.39,
      "duration": 4.17
    },
    {
      "text": "English. We have context-free grammars\nwhere we have one input that doesn't need to",
      "start": 595.56,
      "duration": 6.27
    },
    {
      "text": "look at the context, and we can have many\noutputs and these outputs can",
      "start": 601.83,
      "duration": 4.13
    },
    {
      "text": "communicate with one another and we\nwould need to implement some",
      "start": 605.96,
      "duration": 3.64
    },
    {
      "text": "computational way for them to\ncommunicate, a push down stack for",
      "start": 609.6,
      "duration": 4.26
    },
    {
      "text": "example. So we know that we push so many\nin and we need to pop so many out. A",
      "start": 613.86,
      "duration": 7.58
    },
    {
      "text": "context-sensitive grammar would be one\nthat takes an arbitrary - I'm sorry that",
      "start": 621.44,
      "duration": 6.61
    },
    {
      "text": "takes input and then for every input you\nneed to write an output. You can",
      "start": 628.05,
      "duration": 4.47
    },
    {
      "text": "transform symbols and with this make the\nrule context-sensitive because you need",
      "start": 632.52,
      "duration": 5.04
    },
    {
      "text": "to look at them in order to know what\nyou're doing, but you need to provide for",
      "start": 637.56,
      "duration": 3.69
    },
    {
      "text": "every input an output. Finally an\nunrestricted grammar is one where the rules",
      "start": 641.25,
      "duration": 6.78
    },
    {
      "text": "can take any form. You can take a\nstring and transform into any other",
      "start": 648.03,
      "duration": 3.46
    },
    {
      "text": "string. Human languages probably don't\nhave these, but this is the kind of",
      "start": 651.49,
      "duration": 6.24
    },
    {
      "text": "computa -  of rule that we actually do\nneed in computer science for example. So",
      "start": 657.73,
      "duration": 8.22
    },
    {
      "text": "we can finally make this definition very\nprecise: finite state machines are kind",
      "start": 665.95,
      "duration": 5.1
    },
    {
      "text": "of automaton, a finite state machine is\none that generates regular languages in",
      "start": 671.05,
      "duration": 6.15
    },
    {
      "text": "the form for example a to the nth b to the mth, to the pth. You can generate an arbitrary number of symbols,",
      "start": 677.2,
      "duration": 6.42
    },
    {
      "text": "an arbitrary number of times but they're\nnot gonna be communicating with one",
      "start": 683.62,
      "duration": 4.92
    },
    {
      "text": "another. We can only have transitions\nbetween states so you cannot have",
      "start": 688.54,
      "duration": 8.84
    },
    {
      "text": "communications across distant states in\nfinite state machines. You can have them",
      "start": 697.38,
      "duration": 7.06
    },
    {
      "text": "in other types of grammars but this is\ngonna cost us computationally. This by",
      "start": 704.44,
      "duration": 7.59
    },
    {
      "text": "the way is the same hierarchy just\ndisplayed slightly differently. As you",
      "start": 712.03,
      "duration": 4.86
    },
    {
      "text": "can see we have as finite languages is\nthe most restrictive kinds of languages.",
      "start": 716.89,
      "duration": 5.94
    },
    {
      "text": "Within it, for example, we have logic like\ntrue or false statements. We have rules",
      "start": 722.83,
      "duration": 8.7
    },
    {
      "text": "that are regular, that can be modeled by\nfinite state machines. For example our",
      "start": 731.53,
      "duration": 5.25
    },
    {
      "text": "English consonant clusters have some\nstructure to construct syllables but we",
      "start": 736.78,
      "duration": 5.55
    },
    {
      "text": "only need to look inside of our syllable\nto construct it. We don't need to look at",
      "start": 742.33,
      "duration": 4.02
    },
    {
      "text": "other syllables to know what our\nsyllable needs to look like. We have",
      "start": 746.35,
      "duration": 6.75
    },
    {
      "text": "context free rules, where you need to\nimplement means for the computer to",
      "start": 753.1,
      "duration": 5.79
    },
    {
      "text": "remember what it's doing such as a\nstack, for example, or variables or in",
      "start": 758.89,
      "duration": 4.38
    },
    {
      "text": "some other way so that you can have as\nmany n nouns and as many verbs as you",
      "start": 763.27,
      "duration": 5.7
    },
    {
      "text": "need, but you still don't need to look at\nthe sentences around you.",
      "start": 768.97,
      "duration": 5.3
    },
    {
      "text": "We have at the outside edges of this\nhierarchy, a rule like the Yoruba emphatic",
      "start": 774.4,
      "duration": 8.2
    },
    {
      "text": "where you have a rule that takes a part\nof a syllable, reads it and then",
      "start": 782.6,
      "duration": 6.92
    },
    {
      "text": "generates the output based on what it\nsaw in its immediate con - in its",
      "start": 789.52,
      "duration": 5.02
    },
    {
      "text": "context not just immediate context, but\nit can be context several symbols away,",
      "start": 794.54,
      "duration": 5.16
    },
    {
      "text": "several sounds away like in the second\ncase: sun un. Where you have to go not",
      "start": 799.7,
      "duration": 5.43
    },
    {
      "text": "one but two back and could potentially\ngo even further back and again we don't",
      "start": 805.13,
      "duration": 8.49
    },
    {
      "text": "know if human languages have rules that are\nmore complicated than this. We would call",
      "start": 813.62,
      "duration": 3.27
    },
    {
      "text": "those computationally enumerable rules.\nIn summary human languages do have rules",
      "start": 816.89,
      "duration": 8.46
    },
    {
      "text": "that are context sensitive and that\ncannot be modeled by finite state",
      "start": 825.35,
      "duration": 4.71
    },
    {
      "text": "machines. Some rules in language are\nfairly easy to model and some rules are",
      "start": 830.06,
      "duration": 5.7
    },
    {
      "text": "more complex to model. There's many types\nof formal grammars that we can use to",
      "start": 835.76,
      "duration": 6.06
    },
    {
      "text": "generate computer programs and the\nChomsky hierarchy tells us what - how much",
      "start": 841.82,
      "duration": 5.73
    },
    {
      "text": "power are we gonna need in our computer\nprogram to handle a rule of human",
      "start": 847.55,
      "duration": 5.04
    },
    {
      "text": "language. Next week we're - sorry next week?\nNext video! We're gonna look at the",
      "start": 852.59,
      "duration": 5.73
    },
    {
      "text": "consequences of having to use different\ngrammars and spoiler alert the - the more",
      "start": 858.32,
      "duration": 6.06
    },
    {
      "text": "complex the formal grammar, the more\nwe're gonna have to - more resources we're",
      "start": 864.38,
      "duration": 5.37
    },
    {
      "text": "gonna have to invent - invest for it to\nbe processed, the more costly it's going",
      "start": 869.75,
      "duration": 3.96
    },
    {
      "text": "to be and ultimately the problem is\ngoing to explode out of control.",
      "start": 873.71,
      "duration": 5.93
    }
  ]
}